<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#ddd">
<meta name="generator" content="Hexo 6.0.0">

<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#ddd">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="/lib/@fortawesome/fontawesome-free/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="/lib/animate.css/animate.min.css" integrity="sha256-X7rrn44l1+AUO65h1LGALBbOc5C5bOstSYsNlv9MhT8=" crossorigin="anonymous">
  <link rel="stylesheet" href="/lib/@fancyapps/fancybox/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"blog.imssyang.com","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.9.0","exturl":false,"sidebar":{"position":"right","width":300,"display":"hide","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"rgba(255, 255, 255, 0.1)","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":"disqus","storage":true,"lazyload":false,"nav":{"disqus":{"text":"Disqus","order":-1},"gitalk":{"text":"Github","order":-2}}},"stickytabs":false,"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":3,"unescape":true,"preload":true}}</script><script src="/js/config.js"></script>
<meta name="description" content="å‡ å¹´å‰ï¼Œæœ‰ä½åŒäº‹è¯´å´æ©è¾¾çš„AI (artificial intelligence)æ•™ç¨‹æ˜¯æœ€å¥½äº†ï¼Œå½“æ—¶æ„Ÿè§‰è¿™ä¸ªæ¦‚å¿µç¦»è‡ªå·±è¿˜å¾ˆè¿œï¼Œä¸ä»¥ä¸ºæ„ã€‚æ²¡æˆæƒ³è¿™éº½å¿«ï¼Œopenaiçš„å‡ºç°æ”¹å˜äº†è®¸å¤šäº‹æƒ…ï¼Œå•†ä¸šä¸Šçš„å›¾åƒè¯†åˆ«å’Œè¯­éŸ³è¯†åˆ«ï¼Œåœ¨AIåŠ æŒä¸‹ä¹Ÿè¶Šæ¥è¶Šå¼ºï¼Œç‰¹æ–¯æ‹‰çš„æ™ºèƒ½é©¾é©¶ä¹Ÿæ”¹ç”¨äº†AIæ¨¡å‹ä»£æ›¿ä¼ ç»Ÿç®—æ³•ï¼Œæ˜¯æ—¶å€™ç³»ç»Ÿçš„å­¦ä¹ ä¸‹äº†ã€‚">
<meta property="og:type" content="article">
<meta property="og:title" content="æ·±åº¦å­¦ä¹ åŸºç¡€">
<meta property="og:url" content="https://blog.imssyang.com/DeepLearning/Basic.html">
<meta property="og:site_name" content="Just Do It">
<meta property="og:description" content="å‡ å¹´å‰ï¼Œæœ‰ä½åŒäº‹è¯´å´æ©è¾¾çš„AI (artificial intelligence)æ•™ç¨‹æ˜¯æœ€å¥½äº†ï¼Œå½“æ—¶æ„Ÿè§‰è¿™ä¸ªæ¦‚å¿µç¦»è‡ªå·±è¿˜å¾ˆè¿œï¼Œä¸ä»¥ä¸ºæ„ã€‚æ²¡æˆæƒ³è¿™éº½å¿«ï¼Œopenaiçš„å‡ºç°æ”¹å˜äº†è®¸å¤šäº‹æƒ…ï¼Œå•†ä¸šä¸Šçš„å›¾åƒè¯†åˆ«å’Œè¯­éŸ³è¯†åˆ«ï¼Œåœ¨AIåŠ æŒä¸‹ä¹Ÿè¶Šæ¥è¶Šå¼ºï¼Œç‰¹æ–¯æ‹‰çš„æ™ºèƒ½é©¾é©¶ä¹Ÿæ”¹ç”¨äº†AIæ¨¡å‹ä»£æ›¿ä¼ ç»Ÿç®—æ³•ï¼Œæ˜¯æ—¶å€™ç³»ç»Ÿçš„å­¦ä¹ ä¸‹äº†ã€‚">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/logistic_regression.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/sigmoid_function.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/cross_entropy_function.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/shallow_neural_network.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/activate_sigmoid.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/activate_tanh.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/activate_relu.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/activate_leakyrelu.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/activate_elu.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/activate_softmax.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/shallow_neural_network_sample.jpg">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/deep_neural_network.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/dataset_fitting.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/minibatch_gradient_descent.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/softmax_function.png">
<meta property="og:image" content="https://blog.imssyang.com/images/DeepLearning/onehot_encode.png">
<meta property="article:published_time" content="2024-05-20T04:43:30.000Z">
<meta property="article:modified_time" content="2024-05-20T16:00:00.000Z">
<meta property="article:author" content="Ssyang">
<meta property="article:tag" content="DeepLearning">
<meta property="article:tag" content="ArtificialIntelligence">
<meta property="article:tag" content="NeuralNetwork">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.imssyang.com/images/DeepLearning/logistic_regression.png">


<link rel="canonical" href="https://blog.imssyang.com/DeepLearning/Basic.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://blog.imssyang.com/DeepLearning/Basic.html","path":"DeepLearning/Basic.html","title":"æ·±åº¦å­¦ä¹ åŸºç¡€"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>æ·±åº¦å­¦ä¹ åŸºç¡€ | Just Do It</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Just Do It</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">by Ssyang</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80"><span class="nav-number">1.</span> <span class="nav-text">ç¥ç»ç½‘ç»œåŸºç¡€</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-number">1.1.</span> <span class="nav-text">ç½‘ç»œç»“æ„</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E8%8C%83%E5%BC%8F"><span class="nav-number">1.2.</span> <span class="nav-text">å­¦ä¹ èŒƒå¼</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%EF%BC%88Binary-Classification%EF%BC%89"><span class="nav-number">1.3.</span> <span class="nav-text">äºŒåˆ†ç±»é—®é¢˜ï¼ˆBinary Classificationï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88Logistic-Regression%EF%BC%89"><span class="nav-number">1.3.1.</span> <span class="nav-text">é€»è¾‘å›å½’ï¼ˆLogistic Regressionï¼‰</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%88Gradient-Descent%EF%BC%89"><span class="nav-number">1.3.2.</span> <span class="nav-text">æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E7%A4%BA%E4%BE%8B"><span class="nav-number">1.3.3.</span> <span class="nav-text">è®­ç»ƒç¤ºä¾‹</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%A0%E6%92%AD%EF%BC%88Propagation%EF%BC%89"><span class="nav-number">1.4.</span> <span class="nav-text">ä¼ æ’­ï¼ˆPropagationï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Numpy"><span class="nav-number">1.5.</span> <span class="nav-text">Numpy</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%8C%96%EF%BC%88Vectorization%EF%BC%89"><span class="nav-number">1.5.1.</span> <span class="nav-text">å‘é‡åŒ–ï¼ˆVectorizationï¼‰</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%BF%E6%92%AD%EF%BC%88broadcasting%EF%BC%89"><span class="nav-number">1.5.2.</span> <span class="nav-text">å¹¿æ’­ï¼ˆbroadcastingï¼‰</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88Shallow-NN%EF%BC%89"><span class="nav-number">2.</span> <span class="nav-text">æµ…å±‚ç¥ç»ç½‘ç»œï¼ˆShallow NNï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84"><span class="nav-number">2.1.</span> <span class="nav-text">åŸºæœ¬ç»“æ„</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-number">2.2.</span> <span class="nav-text">å·¥ä½œåŸç†</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%EF%BC%88Activate-Function%EF%BC%89"><span class="nav-number">2.2.1.</span> <span class="nav-text">æ¿€æ´»å‡½æ•°ï¼ˆActivate Functionï¼‰</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%82%E6%95%B0"><span class="nav-number">2.3.</span> <span class="nav-text">åˆå§‹åŒ–å‚æ•°</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E7%A7%B0%E9%97%AE%E9%A2%98%EF%BC%88symmetry-breaking-problem%EF%BC%89"><span class="nav-number">2.3.1.</span> <span class="nav-text">å¯¹ç§°é—®é¢˜ï¼ˆsymmetry breaking problemï¼‰</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="nav-number">2.4.</span> <span class="nav-text">è®¡ç®—è¿‡ç¨‹</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TensorFlow"><span class="nav-number">2.5.</span> <span class="nav-text">TensorFlow</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88Deep-NN%EF%BC%89"><span class="nav-number">3.</span> <span class="nav-text">æ·±å±‚ç¥ç»ç½‘ç»œï¼ˆDeep NNï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%EF%BC%88hyperparameters%EF%BC%89"><span class="nav-number">3.1.</span> <span class="nav-text">è¶…å‚æ•°ï¼ˆhyperparametersï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%88data-set%EF%BC%89"><span class="nav-number">3.2.</span> <span class="nav-text">æ•°æ®é›†ï¼ˆdata setï¼‰</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%81%8F%E5%B7%AE%EF%BC%88Bias%EF%BC%89%E5%92%8C%E6%96%B9%E5%B7%AE%EF%BC%88Variance%EF%BC%89"><span class="nav-number">3.2.1.</span> <span class="nav-text">åå·®ï¼ˆBiasï¼‰å’Œæ–¹å·®ï¼ˆVarianceï¼‰</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%88Regularization%EF%BC%89"><span class="nav-number">3.3.</span> <span class="nav-text">æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%EF%BC%88vanishing-gradient%EF%BC%89"><span class="nav-number">3.4.</span> <span class="nav-text">æ¢¯åº¦æ¶ˆå¤±ï¼ˆvanishing gradientï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%EF%BC%88exploding-gradient%EF%BC%89"><span class="nav-number">3.5.</span> <span class="nav-text">æ¢¯åº¦çˆ†ç‚¸ï¼ˆexploding gradientï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C%EF%BC%88Gradient-Checking%EF%BC%89"><span class="nav-number">3.6.</span> <span class="nav-text">æ¢¯åº¦æ£€éªŒï¼ˆGradient Checkingï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="nav-number">3.7.</span> <span class="nav-text">ä¼˜åŒ–ç®—æ³•</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Mini-Batch"><span class="nav-number">3.7.1.</span> <span class="nav-text">Mini-Batch</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Momentum"><span class="nav-number">3.7.2.</span> <span class="nav-text">Momentum</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RMSprop"><span class="nav-number">3.7.3.</span> <span class="nav-text">RMSprop</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adam"><span class="nav-number">3.7.4.</span> <span class="nav-text">Adam</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F"><span class="nav-number">3.8.</span> <span class="nav-text">å­¦ä¹ ç‡è¡°å‡</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9E%8D%E7%82%B9%EF%BC%88saddle%EF%BC%89"><span class="nav-number">3.9.</span> <span class="nav-text">éç‚¹ï¼ˆsaddleï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Softmax%E5%9B%9E%E5%BD%92"><span class="nav-number">3.10.</span> <span class="nav-text">Softmaxå›å½’</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="nav-number">4.</span> <span class="nav-text">å‚è€ƒèµ„æ–™</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Ssyang"
      src="/images/imssyang/windmill.png">
  <p class="site-author-name" itemprop="name">Ssyang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">34</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/imssyang" title="GitHub â†’ https:&#x2F;&#x2F;github.com&#x2F;imssyang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:imssyang@gmail.com" title="E-Mail â†’ mailto:imssyang@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="/lib/@creativecommons/vocabulary/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.dabeaz.com/" title="https:&#x2F;&#x2F;www.dabeaz.com" rel="noopener" target="_blank">David Beazley</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://coldattic.info/" title="http:&#x2F;&#x2F;coldattic.info" rel="noopener" target="_blank">A Foo Walks into a Bar...</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.brendangregg.com/" title="https:&#x2F;&#x2F;www.brendangregg.com" rel="noopener" target="_blank">Brendan Gregg's Homepage</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.wowza.com/blog" title="https:&#x2F;&#x2F;www.wowza.com&#x2F;blog" rel="noopener" target="_blank">WOWZA Media Systems</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://preshing.com/" title="https:&#x2F;&#x2F;preshing.com" rel="noopener" target="_blank">Preshing on Programming</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.yinwang.org/" title="https:&#x2F;&#x2F;www.yinwang.org" rel="noopener" target="_blank">å½“ç„¶æˆ‘åœ¨æ‰¯æ·¡</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.jianchihu.net/" title="https:&#x2F;&#x2F;blog.jianchihu.net" rel="noopener" target="_blank">å‰‘ç—´ä¹</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://betterexplained.com/" title="https:&#x2F;&#x2F;betterexplained.com" rel="noopener" target="_blank">Better Explained</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.mathsisfun.com/" title="https:&#x2F;&#x2F;www.mathsisfun.com" rel="noopener" target="_blank">Math is Fun</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://notes.shichao.io/" title="https:&#x2F;&#x2F;notes.shichao.io" rel="noopener" target="_blank">Shichao's Notes</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.shuxuele.com/" title="https:&#x2F;&#x2F;www.shuxuele.com" rel="noopener" target="_blank">æ•°å­¦ä¹</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://thispointer.com/" title="https:&#x2F;&#x2F;thispointer.com" rel="noopener" target="_blank">thisPointer</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://refactoring.guru/" title="https:&#x2F;&#x2F;refactoring.guru" rel="noopener" target="_blank">Refactoring.Guru</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blog.imssyang.com/DeepLearning/Basic.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/imssyang/windmill.png">
      <meta itemprop="name" content="Ssyang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Just Do It">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          æ·±åº¦å­¦ä¹ åŸºç¡€
            <div class="post-categories">
              [
                  <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                    <a href="/categories/DeepLearning/" itemprop="url" rel="index"><span itemprop="name">DeepLearning</span></a>
                  </span>
              ]
            </div>
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 5/20/2024 12:43:30" itemprop="dateCreated datePublished" datetime="2024-05-20T12:43:30+08:00">5/20/2024</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 5/21/2024 00:00:00" itemprop="dateModified" datetime="2024-05-21T00:00:00+08:00">5/21/2024</time>
    </span>

  
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>37k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>34 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>å‡ å¹´å‰ï¼Œæœ‰ä½åŒäº‹è¯´å´æ©è¾¾çš„AI (artificial intelligence)æ•™ç¨‹æ˜¯æœ€å¥½äº†ï¼Œå½“æ—¶æ„Ÿè§‰è¿™ä¸ªæ¦‚å¿µç¦»è‡ªå·±è¿˜å¾ˆè¿œï¼Œä¸ä»¥ä¸ºæ„ã€‚æ²¡æˆæƒ³è¿™éº½å¿«ï¼Œopenaiçš„å‡ºç°æ”¹å˜äº†è®¸å¤šäº‹æƒ…ï¼Œå•†ä¸šä¸Šçš„å›¾åƒè¯†åˆ«å’Œè¯­éŸ³è¯†åˆ«ï¼Œåœ¨AIåŠ æŒä¸‹ä¹Ÿè¶Šæ¥è¶Šå¼ºï¼Œç‰¹æ–¯æ‹‰çš„æ™ºèƒ½é©¾é©¶ä¹Ÿæ”¹ç”¨äº†AIæ¨¡å‹ä»£æ›¿ä¼ ç»Ÿç®—æ³•ï¼Œæ˜¯æ—¶å€™ç³»ç»Ÿçš„å­¦ä¹ ä¸‹äº†ã€‚</p>
<span id="more"></span>

<h1 id="ç¥ç»ç½‘ç»œåŸºç¡€"><a href="#ç¥ç»ç½‘ç»œåŸºç¡€" class="headerlink" title="ç¥ç»ç½‘ç»œåŸºç¡€"></a>ç¥ç»ç½‘ç»œåŸºç¡€</h1><p>æ·±åº¦å­¦ä¹ ï¼ˆDeep Learningï¼‰æ˜¯æœºå™¨å­¦ä¹ ï¼ˆMachine Learningï¼‰çš„ä¸€ä¸ªå­é¢†åŸŸï¼ŒåŸºäºäººå·¥ç¥ç»ç½‘ç»œï¼Œå°¤å…¶æ˜¯æ·±åº¦ç¥ç»ç½‘ç»œï¼Œâ€œdeepâ€æŒ‡æ•°æ®è¢«è½¬æ¢çš„å±‚æ•°ï¼ˆlayersï¼‰æˆ–è€…è¯´è½¬æ¢é“¾ï¼ˆcredit assignment path, CAP &gt; 2ï¼‰æ¯”è¾ƒå¤§ï¼Œæ¯ä¸€å±‚å°†å…¶è¾“å…¥æ•°æ®è½¬æ¢ä¸ºæ›´æŠ½è±¡å’Œå¤åˆçš„æ•°æ®è¡¨ç¤ºã€‚</p>
<ul>
<li>â€œæ·±åº¦å­¦ä¹ â€æœ¯è¯­åœ¨1986å¹´è¢«<code>Rina Dechter</code>å¼•å…¥æœºå™¨å­¦ä¹ ï¼ˆmachine learningï¼‰é¢†åŸŸï¼›</li>
<li>1989å¹´<code>Yann LeCun</code>å°†åå‘ä¼ æ’­ç®—æ³•åº”ç”¨åˆ°æ·±åº¦ç¥ç»ç½‘ç»œï¼Œä»¥è¯†åˆ«é‚®ä»¶ä¸Šæ‰‹å†™çš„é‚®æ”¿ç¼–ç ï¼›</li>
<li>1992å¹´ç¥ç»ç½‘ç»œç”¨äºä¸‰ç»´ç‰©ä½“è¯†åˆ«ï¼Œéšååˆåº”ç”¨åœ¨è‚¡ç¥¨é¢„æµ‹å’Œè‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼›</li>
<li>1998å¹´<code>Larry Heck</code>å°†æ·±åº¦ç¥ç»ç½‘ç»œåº”ç”¨åœ¨è¯­éŸ³å¤„ç†ä¸­ï¼Œå·¥ä¸šä¸Šå¤§è§„æ¨¡è¯­éŸ³è¯†åˆ«åº”ç”¨å‡ºç°åœ¨2000å¹´ï¼›</li>
<li>2009å¹´ç¡¬ä»¶è¿›æ­¥é‡æ–°æ¿€å‘äº†äººä»¬å¯¹æ·±åº¦å­¦ä¹ çš„å…´è¶£ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œå¯ä»¥ä½¿ç”¨Nvidia GPUsè¿›è¡Œè®­ç»ƒï¼›</li>
<li>2012å¹´åï¼Œéšç€GPUå’Œåˆ†å¸ƒå¼è®¡ç®—èƒ½åŠ›çš„å¢å¼ºï¼Œä½¿å¾—å¯ä»¥è®­ç»ƒæ›´å¤§çš„ç¥ç»ç½‘ç»œï¼Œç‰¹åˆ«æ˜¯å›¾åƒå’Œè§†è§‰è¯†åˆ«é—®é¢˜ä¸Šï¼›</li>
</ul>
<h2 id="ç½‘ç»œç»“æ„"><a href="#ç½‘ç»œç»“æ„" class="headerlink" title="ç½‘ç»œç»“æ„"></a>ç½‘ç»œç»“æ„</h2><p>äººå·¥ç¥ç»ç½‘ç»œï¼ˆANNs - artificial neural networksï¼‰æ˜¯ä¸€ç§å—å¤§è„‘ä¸­çš„ç”Ÿç‰©ç¥ç»ç½‘ç»œç»“æ„å¯å‘çš„è®¡ç®—ç³»ç»Ÿï¼ŒåŸºäºäººå·¥ç¥ç»å…ƒèŠ‚ç‚¹çš„é›†åˆï¼Œæ¨¡æ‹Ÿç”Ÿç‰©å¤§è„‘ä¸­çš„ç¥ç»å…ƒï¼Œè¯•å›¾æ‰§è¡Œä¼ ç»Ÿç®—æ³•å‡ ä¹æ²¡æœ‰æˆåŠŸè¿‡çš„ä»»åŠ¡ã€‚</p>
<ul>
<li>ä¿¡å·ï¼ˆsignal)ï¼šå®æ•°è¡¨ç¤ºï¼Œæ¯ä¸ªç¥ç»å…ƒçš„è¾“å‡ºæ˜¯å®ƒçš„è¾“å…¥ä¹‹å’Œçš„æŸä¸ªéçº¿æ€§å‡½æ•°ï¼Œå¼ºå¼±é€šè¿‡æƒé‡ï¼ˆweightï¼‰è¡¨ç¤ºã€‚</li>
<li>ç¥ç»å…ƒï¼ˆneuronsï¼‰ï¼šæ¥æ”¶å¤šä¸ªä¿¡å·ï¼Œè®¡ç®—åŠ æƒå’Œï¼ˆç§°ä¸ºæ¿€æ´»ï¼‰ï¼Œè¾¾åˆ°é˜ˆå€¼ï¼ˆthresholdï¼‰åï¼Œå‘ä¸ä¹‹è¿æ¥çš„ç¥ç»å…ƒå‘é€ä¿¡å·ï¼ˆå¤šè¾“å…¥å•è¾“å‡ºï¼‰ã€‚</li>
<li>è¾¹ï¼ˆedgeï¼‰ï¼šç”±ç¥ç»å…ƒç›¸äº’çš„è¿æ¥ç»„æˆã€‚</li>
<li>å±‚ï¼ˆlayerï¼‰ï¼šç”±ç¥ç»å…ƒèšé›†å½¢æˆï¼Œæ¯ä¸€å±‚éƒ½å¯¹è¾“å…¥è¿›è¡Œç‰¹å®šçš„è½¬æ¢ã€‚<ul>
<li>è¾“å…¥å±‚ï¼ˆinput layerï¼‰ï¼šæ¥å—å¤–éƒ¨æ•°æ®çš„å±‚ï¼›</li>
<li>è¾“å‡ºå±‚ï¼ˆoutput layerï¼‰ï¼šäº§ç”Ÿç›®æ ‡ç»“æœçš„å±‚ï¼›</li>
<li>éšè—å±‚ï¼ˆhidden layerï¼‰ï¼šè¾“å…¥å±‚ä¸è¾“å‡ºå±‚ä¹‹é—´çš„å±‚ï¼ˆ&gt;&#x3D;0ï¼‰;</li>
<li>å®Œå…¨è¿æ¥ï¼ˆfully connectedï¼‰ï¼šæ¯ä¸€å±‚çš„æ¯ä¸ªç¥ç»å…ƒéƒ½è¿æ¥åˆ°ä¸‹ä¸€å±‚çš„æ¯ä¸ªç¥ç»å…ƒï¼›</li>
<li>æ± åŒ–è¿æ¥ï¼ˆpooling connectedï¼‰ï¼šæ¯ä¸€å±‚çš„ä¸€ç»„ç¥ç»å…ƒè¿æ¥åˆ°ä¸‹ä¸€å±‚çš„ä¸€ä¸ªç¥ç»å…ƒï¼ˆç¥ç»å…ƒæ•°é‡é€æ¸å‡å°‘ï¼‰ï¼›</li>
<li>å‰é¦ˆç½‘ç»œï¼ˆfeedforward networkï¼‰ï¼šä»…æœ‰æ± åŒ–è¿æ¥ç»„æˆçš„ç¥ç»ç½‘ç»œï¼ˆæœ‰å‘æ— ç¯å›¾ï¼Œdirected acyclic graphï¼‰ï¼›</li>
<li>å¾ªç¯ç½‘ç»œï¼ˆrecurrent networkï¼‰ï¼šå…è®¸åŒä¸€å±‚æˆ–å‰ä¸€å±‚ç¥ç»å…ƒä¹‹é—´è¿æ¥çš„ç½‘ç»œï¼›</li>
</ul>
</li>
</ul>
<h2 id="å­¦ä¹ èŒƒå¼"><a href="#å­¦ä¹ èŒƒå¼" class="headerlink" title="å­¦ä¹ èŒƒå¼"></a>å­¦ä¹ èŒƒå¼</h2><ul>
<li>ç›‘ç£å­¦ä¹ ï¼ˆsupervised learningï¼‰ï¼šä½¿ç”¨ä¸€ç»„æˆå¯¹çš„è¾“å…¥å’ŒæœŸæœ›çš„è¾“å‡ºï¼Œé€šè¿‡å‡æ–¹å·®ï¼ˆmean-squared errorï¼‰ä½œä¸ºä»£ä»·å‡½æ•°è¯„ä¼°è¯¯å·®ï¼›<ul>
<li>é€‚åˆæ¨¡å¼è¯†åˆ«ï¼ˆpattern recognition, or classificationï¼‰å’Œå›å½’ï¼ˆregression, or function approximationï¼‰ï¼›</li>
<li>é€‚åˆé¡ºåºæ•°æ®ï¼Œä¾‹å¦‚æ‰‹å†™ã€è¯­éŸ³è¯†åˆ«å’Œæ‰‹åŠ¿è¯†åˆ«ï¼›</li>
</ul>
</li>
<li>æ— ç›‘ç£å­¦ä¹ ï¼ˆunsupervised learningï¼‰</li>
<li>å¼ºåŒ–å­¦ä¹ ï¼ˆreinforcement learningï¼‰</li>
<li>è‡ªå­¦ä¹ ï¼ˆself-learningï¼‰</li>
<li>ç¥ç»æ¼”åŒ–ï¼ˆneuroevolutionï¼‰</li>
</ul>
<h2 id="äºŒåˆ†ç±»é—®é¢˜ï¼ˆBinary-Classificationï¼‰"><a href="#äºŒåˆ†ç±»é—®é¢˜ï¼ˆBinary-Classificationï¼‰" class="headerlink" title="äºŒåˆ†ç±»é—®é¢˜ï¼ˆBinary Classificationï¼‰"></a>äºŒåˆ†ç±»é—®é¢˜ï¼ˆBinary Classificationï¼‰</h2><p>ä¸€å¼ <code>64x64</code>åƒç´ çš„å›¾ç‰‡ä½œä¸ºè¾“å…¥ï¼Œè¯†åˆ«åˆ°çŒ«è¾“å‡º<code>1</code>ï¼Œæœªè¯†åˆ«åˆ°è¾“å‡º<code>0</code>ã€‚</p>
<h3 id="é€»è¾‘å›å½’ï¼ˆLogistic-Regressionï¼‰"><a href="#é€»è¾‘å›å½’ï¼ˆLogistic-Regressionï¼‰" class="headerlink" title="é€»è¾‘å›å½’ï¼ˆLogistic Regressionï¼‰"></a>é€»è¾‘å›å½’ï¼ˆLogistic Regressionï¼‰</h3><ul>
<li>é€»è¾‘å›å½’ï¼ˆlogistic regressionï¼‰æ˜¯ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„äºŒåˆ†ç±»ç®—æ³•ï¼Œé€šè¿‡å°†çº¿æ€§å›å½’çš„ç»“æœé€šè¿‡ <code>sigmoid</code> å‡½æ•°æ˜ å°„åˆ° <code>[0, 1]</code> åŒºé—´ï¼Œä»è€Œå¾—åˆ°åˆ†ç±»çš„æ¦‚ç‡ã€‚<ul>
<li><strong>æ¿€æ´»å‡½æ•°æˆ–å‡è®¾å‡½æ•°ï¼ˆHypothesis Functionï¼‰</strong>æ˜¯æŒ‡æ¨¡å‹ç”¨æ¥é¢„æµ‹è¾“å‡ºçš„å‡½æ•°ã€‚å¯¹äºé€»è¾‘å›å½’ï¼Œå‡è®¾å‡½æ•° $h(x)$ å°±æ˜¯ä¸Šé¢çš„ sigmoid å‡½æ•°ã€‚</li>
<li><strong>æŸå¤±å‡½æ•°ï¼ˆLoss Functionï¼‰</strong>æ˜¯ç”¨äºè¡¡é‡æ¨¡å‹é¢„æµ‹ä¸å®é™…è§‚æµ‹ä¹‹é—´è¯¯å·®çš„å‡½æ•°ã€‚å®ƒæ˜¯ä¼˜åŒ–æ¨¡å‹çš„ç›®æ ‡å‡½æ•°ï¼Œé€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°æ¥è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä½¿æ¨¡å‹é¢„æµ‹å°½å¯èƒ½æ¥è¿‘çœŸå®å€¼ã€‚</li>
<li><strong>å‡¸å‡½æ•°ï¼ˆConvex functionï¼‰</strong>çš„å›¾åƒæ˜¯ä¸€ä¸ªå½¢çŠ¶å‘ä¸Šçš„ç¢—ã€‚å‡¸å‡½æ•°æœ‰ä¸€ä¸ªå¾ˆé‡è¦çš„æ€§è´¨ï¼šä»»ä½•å±€éƒ¨æœ€å°å€¼ä¹Ÿæ˜¯å…¨å±€æœ€å°å€¼ã€‚</li>
</ul>
</li>
</ul>
<p>é€»è¾‘å›å½’çš„ç½‘ç»œç»“æ„ï¼š<br><img data-src="/images/DeepLearning/logistic_regression.png"></p>
<p>è®¡ç®—æœºä»¥çº¢ã€ç»¿ã€è“ä¸‰ç§é¢œè‰²é€šé“å­˜å‚¨åƒç´ ï¼Œå°†åƒç´ å€¼å®šä¹‰ä¸ºä¸€ä¸ªè¾“å…¥ç‰¹å¾å‘é‡$X$:<br>$$ X&#x3D;n_x&#x3D;[x_1, x_2, â€¦, x_n]ï¼Œå…¶ä¸­ n&#x3D;64 \times 64 \times 3&#x3D;12288 $$</p>
<p>å®šä¹‰ä¸¤ä¸ªæ¨¡å‹å‚æ•°ï¼Œç‰¹å¾æƒé‡$W$å’Œåå·®$b$ï¼ˆå®æ•°å€¼ï¼‰ï¼š<br>$$ W&#x3D;n_w&#x3D;[w_1, w_2, â€¦, w_n]ï¼Œå…¶ä¸­ n åŒ X å‘é‡ä¸€è‡´ $$</p>
<p>é‚£ä¹ˆï¼Œçº¿æ€§ç»„åˆ$z$å¯ä»¥è¡¨ç¤ºä¸ºï¼š<br>$$ z&#x3D;wâ‹…x+b $$</p>
<p>ç„¶åï¼Œå°†çº¿æ€§å›å½’çš„ç»“æœåº”ç”¨ sigmoid å‡½æ•°å¾—åˆ°è¾“å‡ºæ¦‚ç‡ ğ‘ï¼š<br>$$ p &#x3D; \sigma(z) &#x3D; \frac{1}{1 + e^{-z}} $$</p>
<p><img data-src="/images/DeepLearning/sigmoid_function.png"></p>
<p>è¾“å‡ºç»“æœç”¨$y$è¡¨ç¤ºï¼Œæ¦‚ç‡å€¼$ğ‘$è¡¨ç¤ºå¤„ç†è¾“å…¥ç‰¹å¾$X$å$y&#x3D;1$çš„æ¦‚ç‡ï¼Œé€šå¸¸ä¼šé€‰æ‹©ä¸€ä¸ªé˜ˆå€¼ï¼ˆä¾‹å¦‚ 0.5ï¼‰ï¼š<br>$$ ğ‘ &gt; 0.5 æ—¶ï¼Œy&#x3D;1ï¼Œè¯†åˆ«åˆ°çŒ« $$<br>$$ ğ‘ &lt;&#x3D; 0.5 æ—¶ï¼Œy&#x3D;0ï¼Œæœªè¯†åˆ«åˆ°çŒ« $$</p>
<p>åœ¨ç›‘ç£å­¦ä¹ ä¸­ï¼ŒæŸå¤±å‡½æ•° $L(y, \hat{y})$ ç”¨äºè¡¡é‡é¢„æµ‹å€¼ $\hat{y}$ å’ŒçœŸå®å€¼ $ğ‘¦$ ä¹‹é—´çš„å·®å¼‚ã€‚å¯¹äºåˆ†ç±»é—®é¢˜ï¼Œå¸¸ç”¨äº¤å‰ç†µæŸå¤±ï¼ˆCross-Entropy Lossï¼‰ä½œä¸ºæŸå¤±å‡½æ•°ï¼š<br>$$ L(y, \hat{y}) &#x3D; -[ y \log(\hat{y}) + (1 - y) \log(1 - \hat{y})] $$</p>
<p>å¯¹äºæ•´ä¸ªè®­ç»ƒé›†ï¼ŒæŸå¤±å‡½æ•°çš„æ€»å’Œï¼ˆæˆ–å¹³å‡ï¼‰$J(w, b)$æ˜¯ï¼š<br>$$ J(w, b) &#x3D; -\frac{1}{m} \sum_{i&#x3D;1}^{m} \left[ y_i \log(\hat{y_i}) + (1 - y_i) \log(1 - \hat{y_i}) \right] $$<br>$$ m æ˜¯æ ·æœ¬ï¼ˆç¤ºä¾‹æŒ‡å›¾ç‰‡ï¼‰çš„æ•°é‡ $$<br>$$ ğ‘¦_ğ‘– æ˜¯ç¬¬ ğ‘– ä¸ªæ ·æœ¬çš„çœŸå®æ ‡ç­¾ï¼ˆ0 æˆ– 1ï¼‰ $$<br>$$ \hat{y_i} æ˜¯ç¬¬ ğ‘– ä¸ªæ ·æœ¬é¢„æµ‹ä¸ºç±»åˆ« 1 çš„æ¦‚ç‡ $$</p>
<p><strong>å¯¹äºäºŒåˆ†ç±»é—®é¢˜ï¼Œäº¤å‰ç†µæŸå¤±å‡½æ•°å…³äºé¢„æµ‹æ¦‚ç‡ $\hat{y}$ æ˜¯å‡¸å‡½æ•°</strong>ï¼š<br>$$ å½“ y&#x3D;1 æ—¶ï¼Œ L(\hat{y}) &#x3D; -\log(\hat{y})ï¼Œä¸ºäº†æŸå¤±å‡½æ•°çš„å€¼å°½å¯èƒ½å°ï¼Œè¦æ±‚\hat{y}çš„å€¼è¦å°½å¯èƒ½å¤§ï¼ˆæ— é™æ¥è¿‘1ï¼‰ $$<br>$$ å½“ y&#x3D;0 æ—¶ï¼Œ L(\hat{y}) &#x3D; -\log(1 - \hat{y})ï¼Œä¸ºäº†æŸå¤±å‡½æ•°çš„å€¼å°½å¯èƒ½å°ï¼Œè¦æ±‚\hat{y}çš„å€¼è¦å°½å¯èƒ½å°ï¼ˆæ— é™æ¥è¿‘0ï¼‰ $$</p>
<p><img data-src="/images/DeepLearning/cross_entropy_function.png"></p>
<p><strong>è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹çš„ç›®æ ‡æ˜¯æ‰¾åˆ°æœ€ä¼˜çš„å‚æ•° $ğ‘¤$ å’Œ $ğ‘$ï¼Œä½¿å¾—æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„é¢„æµ‹å°½å¯èƒ½å‡†ç¡®ã€‚</strong></p>
<h3 id="æ¢¯åº¦ä¸‹é™ï¼ˆGradient-Descentï¼‰"><a href="#æ¢¯åº¦ä¸‹é™ï¼ˆGradient-Descentï¼‰" class="headerlink" title="æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰"></a>æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰</h3><p>æ¢¯åº¦ä¸‹é™æ³•ï¼ˆGradient Descentï¼‰æ˜¯æ·±åº¦å­¦ä¹ ä¸­ç”¨äºä¼˜åŒ–æ¨¡å‹å‚æ•°çš„ä¸€ç§é‡è¦ç®—æ³•ã€‚å¯¹äºå‡¸å‡½æ•°ï¼Œæ¢¯åº¦ä¸‹é™æ³•çš„è¡¨ç°éå¸¸å¥½ï¼Œå› ä¸ºï¼š</p>
<ul>
<li>å”¯ä¸€çš„å…¨å±€æœ€å°å€¼ï¼šç”±äºå‡¸å‡½æ•°çš„æ€§è´¨ï¼Œä»»ä½•å±€éƒ¨æœ€å°å€¼éƒ½æ˜¯å…¨å±€æœ€å°å€¼ã€‚è¿™æ„å‘³ç€æ¢¯åº¦ä¸‹é™æ³•ä¸ä¼šé™·å…¥å±€éƒ¨æœ€å°å€¼ã€‚</li>
<li>æ”¶æ•›æ€§ï¼šæ¢¯åº¦ä¸‹é™æ³•åœ¨å‡¸å‡½æ•°ä¸Šé€šå¸¸æœ‰è‰¯å¥½çš„æ”¶æ•›æ€§å’Œç¨³å®šæ€§ï¼Œåªè¦å­¦ä¹ ç‡é€‚å½“ï¼Œç®—æ³•å°±èƒ½é€æ­¥æ¥è¿‘å…¨å±€æœ€å°å€¼ã€‚</li>
</ul>
<p>æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼šé€šè¿‡è¿­ä»£æ›´æ–°æ¨¡å‹å‚æ•° $ğ‘¤$ å’Œ $ğ‘$ï¼Œæœ€å°åŒ–æŸå¤±å‡½æ•° $ğ½(ğ‘¤,ğ‘)$ï¼Œä»è€Œä½¿æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„é¢„æµ‹æ›´åŠ å‡†ç¡®ã€‚</p>
<ol>
<li>åˆå§‹åŒ–å‚æ•°ï¼šéšæœºåˆå§‹åŒ– $ğ‘¤$ å’Œ $ğ‘$ã€‚</li>
<li>è®¡ç®—é¢„æµ‹å€¼ï¼šä½¿ç”¨å½“å‰çš„å‚æ•°è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹æ¦‚ç‡ $\hat{y}^ğ‘–$ã€‚</li>
<li>è®¡ç®—æŸå¤±ï¼šè®¡ç®—äº¤å‰ç†µæŸå¤±å‡½æ•°çš„å€¼ã€‚</li>
<li>è®¡ç®—æ¢¯åº¦ï¼š</li>
</ol>
<ul>
<li>è®¡ç®—æŸå¤±å‡½æ•°ç›¸å¯¹äº $ğ‘¤$ çš„æ¢¯åº¦ï¼ˆåå¯¼æ•°ï¼‰:<br>  $$ \frac{\partial J}{\partial \mathbf{w}} &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^{m} \left( \hat{y}^{(i)} - y^{(i)} \right) \mathbf{x}^{(i)} $$</li>
<li>è®¡ç®—æŸå¤±å‡½æ•°ç›¸å¯¹äº $b$ çš„æ¢¯åº¦ï¼ˆåå¯¼æ•°ï¼‰:<br>  $$ \frac{\partial J}{\partial b} &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^{m} \left( \hat{y}^{(i)} - y^{(i)} \right) $$</li>
</ul>
<ol start="5">
<li>æ›´æ–°å‚æ•°: $ğ›¼$ æ˜¯å­¦ä¹ ç‡ï¼ˆlearning rateï¼‰ï¼Œæ§åˆ¶å‚æ•°æ›´æ–°çš„æ­¥é•¿ï¼ˆstepï¼‰ï¼š</li>
</ol>
<ul>
<li>æ›´æ–°æƒé‡å‘é‡ $ğ‘¤$ï¼š<br>  $$ \mathbf{w} :&#x3D; \mathbf{w} - \alpha \frac{\partial J}{\partial \mathbf{w}} $$</li>
<li>æ›´æ–°åå·® $b$ï¼š<br>  $$ b :&#x3D; b - \alpha \frac{\partial J}{\partial b} $$</li>
</ul>
<ol start="6">
<li>é‡å¤æ­¥éª¤ï¼šé‡å¤æ­¥éª¤ 2 åˆ° 5ï¼Œç›´åˆ°æŸå¤±å‡½æ•°æ”¶æ•›æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚</li>
</ol>
<p>ç†è§£æ¢¯åº¦ä¸‹é™</p>
<ul>
<li>æ¢¯åº¦çš„æ–¹å‘ï¼šæ¢¯åº¦ $âˆ‡J(w,b)$ æŒ‡å‘æŸå¤±å‡½æ•°ä¸Šå‡æœ€å¿«çš„æ–¹å‘ã€‚ä¸ºäº†æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Œæˆ‘ä»¬æ²¿ç€æ¢¯åº¦çš„åæ–¹å‘æ›´æ–°å‚æ•°ã€‚</li>
<li>å­¦ä¹ ç‡ï¼šå­¦ä¹ ç‡ $ğ›¼$ å†³å®šäº†æ¯æ¬¡æ›´æ–°çš„æ­¥é•¿ã€‚é€‰æ‹©åˆé€‚çš„å­¦ä¹ ç‡éå¸¸é‡è¦ï¼š<ul>
<li>å¦‚æœ $ğ›¼$ å¤ªå¤§ï¼Œå¯èƒ½ä¼šå¯¼è‡´å‚æ•°åœ¨æœ€ä¼˜å€¼é™„è¿‘æŒ¯è¡æˆ–å‘æ•£ã€‚</li>
<li>å¦‚æœ $ğ›¼$ å¤ªå°ï¼Œæ”¶æ•›é€Ÿåº¦ä¼šå¾ˆæ…¢ã€‚</li>
</ul>
</li>
<li>æ”¶æ•›æ¡ä»¶ï¼šé€šå¸¸è®¾å®šæ”¶æ•›æ¡ä»¶ï¼Œå¦‚æŸå¤±å‡½æ•°çš„å˜åŒ–å°äºæŸä¸ªé˜ˆå€¼ï¼Œæˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚</li>
</ul>
<h3 id="è®­ç»ƒç¤ºä¾‹"><a href="#è®­ç»ƒç¤ºä¾‹" class="headerlink" title="è®­ç»ƒç¤ºä¾‹"></a>è®­ç»ƒç¤ºä¾‹</h3><div class="tabs" id="deeplearning-gradient-descent"><ul class="nav-tabs"><li class="tab active"><a href="#deeplearning-gradient-descent-1">(w-5)^2</a></li><li class="tab"><a href="#deeplearning-gradient-descent-2">äºŒåˆ†ç±»</a></li></ul><div class="tab-content"><div class="tab-pane active" id="deeplearning-gradient-descent-1"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å‡è®¾æœ‰ä¸€ä¸ªæŸå¤±å‡½æ•° J(w) = w^2 - 10w + 25 = (w-5)^2 éœ€è¦æœ€å°åŒ–ï¼Œç›®æ ‡å€¼ w=5ã€‚</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&quot;TF_USE_LEGACY_KERAS&quot;</span>] = <span class="string">&quot;True&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¡®ä¿æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ TensorFlow 2.x</span></span><br><span class="line"><span class="keyword">assert</span> tf.__version__.startswith(<span class="string">&#x27;2.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰å‚æ•° w</span></span><br><span class="line">w = tf.Variable(<span class="number">0.0</span>, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰æŸå¤±å‡½æ•°</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cost_fn</span>():</span><br><span class="line">    coefficients = np.array([<span class="number">1.</span>, -<span class="number">10.</span>, <span class="number">25.</span>])</span><br><span class="line">    <span class="keyword">return</span> coefficients[<span class="number">0</span>] * w**<span class="number">2</span> + coefficients[<span class="number">1</span>] * w + coefficients[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨æ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ä¸º 0.01</span></span><br><span class="line">optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒæ­¥éª¤</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    optimizer.minimize(cost_fn, var_list=[w])</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:  <span class="comment"># æ¯ 100 æ¬¡æ‰“å°ä¸€æ¬¡ w çš„å€¼</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Step <span class="subst">&#123;i&#125;</span>: w = <span class="subst">&#123;w.numpy()&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Final w = <span class="subst">&#123;w.numpy()&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 0: w = 0.09999999403953552</span></span><br><span class="line"><span class="comment"># Step 100: w = 4.350164413452148</span></span><br><span class="line"><span class="comment"># Step 200: w = 4.913819789886475</span></span><br><span class="line"><span class="comment"># Step 300: w = 4.988570690155029</span></span><br><span class="line"><span class="comment"># Step 400: w = 4.998484134674072</span></span><br><span class="line"><span class="comment"># Step 500: w = 4.9997992515563965</span></span><br><span class="line"><span class="comment"># Step 600: w = 4.999971866607666</span></span><br><span class="line"><span class="comment"># Step 700: w = 4.999988555908203</span></span><br><span class="line"><span class="comment"># Step 800: w = 4.999988555908203</span></span><br><span class="line"><span class="comment"># Step 900: w = 4.999988555908203</span></span><br><span class="line"><span class="comment"># Final w = 4.999988555908203</span></span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="deeplearning-gradient-descent-2"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç”Ÿæˆä¸€ä¸ªç®€å•çš„äºŒåˆ†ç±»æ•°æ®é›†</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)  <span class="comment"># ä¸ºäº†ç»“æœå¯é‡å¤</span></span><br><span class="line">num_samples = <span class="number">100</span></span><br><span class="line">num_features = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç”Ÿæˆéšæœºæ•°æ®ç‚¹</span></span><br><span class="line">X = np.random.randn(num_samples, num_features)</span><br><span class="line"><span class="comment"># ç”Ÿæˆéšæœºæ ‡ç­¾ (0 æˆ– 1)</span></span><br><span class="line">y = (np.random.rand(num_samples) &gt; <span class="number">0.5</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ·»åŠ åå·®ç‰¹å¾ï¼ˆåˆ—ï¼‰åˆ°è¾“å…¥æ•°æ®çŸ©é˜µX</span></span><br><span class="line">X = np.hstack((X, np.ones((num_samples, <span class="number">1</span>))))</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆå§‹åŒ–å‚æ•°</span></span><br><span class="line">w = np.random.randn(num_features + <span class="number">1</span>)</span><br><span class="line">b = <span class="number">0.0</span></span><br><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line">num_iterations = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">    <span class="comment"># è®¡ç®—é¢„æµ‹å€¼</span></span><br><span class="line">    z = np.dot(X, w) + b</span><br><span class="line">    y_hat = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># è®¡ç®—æŸå¤±</span></span><br><span class="line">    loss = -np.mean(y * np.log(y_hat) + (<span class="number">1</span> - y) * np.log(<span class="number">1</span> - y_hat))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># è®¡ç®—æ¢¯åº¦</span></span><br><span class="line">    dw = np.dot(X.T, (y_hat - y)) / num_samples</span><br><span class="line">    db = np.mean(y_hat - y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ›´æ–°å‚æ•°</span></span><br><span class="line">    w -= alpha * dw</span><br><span class="line">    b -= alpha * db</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ‰“å°æŸå¤±å€¼ï¼ˆå¯é€‰ï¼‰</span></span><br><span class="line">    <span class="keyword">if</span> iteration % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Iteration <span class="subst">&#123;iteration&#125;</span>, Loss: <span class="subst">&#123;loss&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training complete.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Final weights: <span class="subst">&#123;w&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Final bias: <span class="subst">&#123;b&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Iteration 0, Loss: 1.045403457065729</span></span><br><span class="line"><span class="comment"># Iteration 100, Loss: 0.8725920935904518</span></span><br><span class="line"><span class="comment"># Iteration 200, Loss: 0.7728200927540975</span></span><br><span class="line"><span class="comment"># Iteration 300, Loss: 0.7221046768380543</span></span><br><span class="line"><span class="comment"># Iteration 400, Loss: 0.6982084324634529</span></span><br><span class="line"><span class="comment"># Iteration 500, Loss: 0.6872343716236392</span></span><br><span class="line"><span class="comment"># Iteration 600, Loss: 0.6821316667101349</span></span><br><span class="line"><span class="comment"># Iteration 700, Loss: 0.6796706673755826</span></span><br><span class="line"><span class="comment"># Iteration 800, Loss: 0.6784256089360546</span></span><br><span class="line"><span class="comment"># Iteration 900, Loss: 0.6777644058163474</span></span><br><span class="line"><span class="comment"># Training complete.</span></span><br><span class="line"><span class="comment"># Final weights: [ 0.06850934 -0.26623629 -1.10926574]</span></span><br><span class="line"><span class="comment"># Final bias: 0.9214187234747546</span></span><br></pre></td></tr></table></figure></div></div></div>

<h2 id="ä¼ æ’­ï¼ˆPropagationï¼‰"><a href="#ä¼ æ’­ï¼ˆPropagationï¼‰" class="headerlink" title="ä¼ æ’­ï¼ˆPropagationï¼‰"></a>ä¼ æ’­ï¼ˆPropagationï¼‰</h2><ul>
<li>é“¾å¼æ³•åˆ™ï¼ˆChain Ruleï¼‰æ˜¯å¾®ç§¯åˆ†ä¸­çš„ä¸€ä¸ªåŸºæœ¬å®šç†ï¼Œç”¨äºè®¡ç®—å¤åˆå‡½æ•°å¯¼æ•°çš„åŸºæœ¬å®šç†ï¼š<br>$$ å¯¹äºå¤åˆå‡½æ•° f(g(x)), å®ƒç›¸å¯¹äº x çš„å¯¼æ•°å¯ä»¥è¡¨ç¤ºä¸º \frac{df}{dx} &#x3D; \frac{df}{dg} â‹… \frac{dg}{dx} $$</li>
<li>è®¡ç®—å›¾ï¼ˆComputation Graphï¼‰ï¼šæ˜¯ä¸€ç§åœ¨æ·±åº¦å­¦ä¹ ä¸­ç”¨äºæè¿°æ•°å­¦è¿ç®—å’Œå˜é‡ä¾èµ–å…³ç³»çš„æœ‰å‘å›¾ã€‚</li>
<li>è‡ªåŠ¨å¾®åˆ†ï¼ˆAutomatic Differentiationï¼‰æ˜¯ä¸€ç§é€šè¿‡æ„å»ºè®¡ç®—å›¾å¹¶åº”ç”¨é“¾å¼æ³•åˆ™ï¼Œé«˜æ•ˆè®¡ç®—å‡½æ•°æ¢¯åº¦çš„æ–¹æ³•ï¼š<ul>
<li>æ­£å‘æ¨¡å¼ï¼ˆforward modeï¼‰ï¼šä»è¾“å…¥å¼€å§‹ï¼Œé€æ­¥è®¡ç®—æ¯ä¸ªä¸­é—´å˜é‡çš„å¯¼æ•°ã€‚</li>
<li>åå‘æ¨¡å¼ï¼ˆreverse modeï¼‰ï¼šä»è¾“å‡ºå¼€å§‹ï¼Œé€æ­¥è®¡ç®—æ¯ä¸ªå˜é‡å¯¹æœ€ç»ˆè¾“å‡ºçš„å¯¼æ•°ã€‚</li>
</ul>
</li>
<li>ç¥ç»ç½‘ç»œï¼š<ul>
<li>å‰å‘ä¼ æ’­(foward propagation)ï¼šç”¨äºè¡¨ç¤ºå‰å‘ä¼ æ’­çš„è®¡ç®—è¿‡ç¨‹ï¼Œä»è¾“å…¥åˆ°è¾“å‡ºé€å±‚è®¡ç®—ã€‚</li>
<li>åå‘ä¼ æ’­(backward propagation)ï¼šå¯ä»¥ä»è¾“å‡ºå¼€å§‹ï¼Œåå‘è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„æ¢¯åº¦ï¼Œè¿™æ˜¯æ¢¯åº¦ä¸‹é™ç®—æ³•çš„åŸºç¡€ï¼Œåˆ©ç”¨é“¾å¼æ³•åˆ™æ¥è®¡ç®—æ¯ä¸ªå‚æ•°å¯¹æŸå¤±å‡½æ•°çš„æ¢¯åº¦ã€‚</li>
</ul>
</li>
</ul>
<div class="tabs" id="deeplearning-propagation"><ul class="nav-tabs"><li class="tab active"><a href="#deeplearning-propagation-1">$ ğ‘§ = (x_1 + 2x_2) â‹… x_3 $</a></li><li class="tab"><a href="#deeplearning-propagation-2">äºŒåˆ†ç±»</a></li></ul><div class="tab-content"><div class="tab-pane active" id="deeplearning-propagation-1"><p>è€ƒè™‘ä¸€ä¸ªç®€å•çš„å‰å‘ä¼ æ’­è¿‡ç¨‹ï¼Œå‡½æ•°è¡¨è¾¾å¼ä¸ºï¼š<br>$$ ğ‘§ &#x3D; x_1 + 2x_2 $$<br>$$ ğ‘ &#x3D; ğ‘§ â‹… x_3 $$</p>
<p>è®¡ç®—å›¾å¯ä»¥è¡¨ç¤ºå¦‚ä¸‹ï¼š</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x1 -------</span><br><span class="line">          Add --&gt; z --</span><br><span class="line">x2 -*-2---+           |</span><br><span class="line">                    Mul ---&gt; a</span><br><span class="line">x3 -------------------</span><br></pre></td></tr></table></figure>

<p>è®¡ç®—å„å˜é‡çš„åå¯¼æ•°ï¼š<br>$ \frac{âˆ‚ğ‘}{âˆ‚ğ‘§} &#x3D; x_3 $<br>$ \frac{âˆ‚ğ‘}{âˆ‚x_3} &#x3D; ğ‘§ $<br>$ \frac{âˆ‚ğ‘§}{âˆ‚x_1} &#x3D; 1 $<br>$ \frac{âˆ‚ğ‘§}{âˆ‚x_2} &#x3D; 2 $</p>
<p>é€šè¿‡é“¾å¼æ³•åˆ™è®¡ç®—åå‘ä¼ æ’­æ¢¯åº¦ï¼š<br>$ \frac{âˆ‚ğ‘}{âˆ‚x_1} &#x3D; \frac{âˆ‚ğ‘}{âˆ‚ğ‘§} â‹… \frac{âˆ‚ğ‘§}{âˆ‚x_1} &#x3D; x_3 â‹… 1 &#x3D; x_3 $<br>$ \frac{âˆ‚ğ‘}{âˆ‚x_2} &#x3D; \frac{âˆ‚ğ‘}{âˆ‚ğ‘§} â‹… \frac{âˆ‚ğ‘§}{âˆ‚x_2} &#x3D; x_3 â‹… 2 &#x3D; 2x_3 $<br>$ \frac{âˆ‚ğ‘}{âˆ‚x_3} &#x3D; ğ‘§ &#x3D; x_1 + 2x_2 $</p>
<p>PyTorch ä½¿ç”¨è‡ªåŠ¨å¾®åˆ†è¿›è¡Œåå‘ä¼ æ’­çš„ç¤ºä¾‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰è¾“å…¥å¼ é‡</span></span><br><span class="line">x1 = torch.tensor([<span class="number">1.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">x2 = torch.tensor([<span class="number">2.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">x3 = torch.tensor([<span class="number">3.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¡ç®—è¾“å‡º</span></span><br><span class="line">z = (x1 + <span class="number">2</span> * x2) * x3</span><br><span class="line"></span><br><span class="line"><span class="comment"># åå‘ä¼ æ’­</span></span><br><span class="line">z.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å‡ºæ¢¯åº¦</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Gradient of x1:&quot;</span>, x1.grad.item())  <span class="comment"># 3.0</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Gradient of x2:&quot;</span>, x2.grad.item())  <span class="comment"># 6.0</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Gradient of x3:&quot;</span>, x3.grad.item())  <span class="comment"># 5.0</span></span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="deeplearning-propagation-2"><p>è€ƒè™‘ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œï¼Œè¾“å…¥ $ğ‘¥$ï¼Œæƒé‡ $ğ‘¤$ï¼Œåå·® $ğ‘$ï¼Œè¾“å‡º $ğ‘¦$ï¼ŒæŸå¤±å‡½æ•° $ğ¿$ã€‚å‰å‘ä¼ æ’­è¿‡ç¨‹å¦‚ä¸‹ï¼š<br>$$ çº¿æ€§ç»„åˆå‡½æ•°ï¼šz &#x3D; w â‹… x + b $$<br>$$ æ¿€æ´»å‡½æ•°ï¼šğ‘ &#x3D; ğœ(ğ‘§) $$<br>$$ æŸå¤±å‡½æ•°ï¼šğ¿ &#x3D; (ğ‘ âˆ’ ğ‘¦)^2 $$</p>
<p>è®¡ç®—å„å˜é‡çš„å¯¼æ•°ï¼š<br>$$ æŸå¤±å‡½æ•°ç›¸å¯¹äºæ¿€æ´»å€¼çš„å¯¼æ•°ï¼š\frac{âˆ‚L}{âˆ‚ğ‘} &#x3D; 2(aâˆ’y) $$<br>$$ æ¿€æ´»å€¼ç›¸å¯¹äºçº¿æ€§ç»„åˆçš„å¯¼æ•°ï¼š\frac{âˆ‚ğ‘}{âˆ‚z} &#x3D; Ïƒ^â€²(z) &#x3D; Ïƒ(z)(1âˆ’Ïƒ(z)) $$<br>$$ çº¿æ€§ç»„åˆç›¸å¯¹äºæƒé‡å’Œè¾“å…¥çš„å¯¼æ•°ï¼š$$<br>$$ \frac{âˆ‚z}{âˆ‚w} &#x3D; x $$<br>$$ \frac{âˆ‚z}{âˆ‚x} &#x3D; w $$<br>$$ \frac{âˆ‚z}{âˆ‚b} &#x3D; 1 $$<br>$$ é“¾å¼æ³•åˆ™è®¡ç®—æŸå¤±å‡½æ•°ç›¸å¯¹äºæƒé‡ã€è¾“å…¥å’Œåå·®çš„å¯¼æ•°ï¼š$$<br>$$ \frac{âˆ‚L}{âˆ‚z} &#x3D; \frac{âˆ‚L}{âˆ‚ğ‘} â‹… \frac{âˆ‚ğ‘}{âˆ‚z} $$<br>$$ \frac{âˆ‚L}{âˆ‚w} &#x3D; \frac{âˆ‚L}{âˆ‚z} â‹… \frac{âˆ‚z}{âˆ‚w} &#x3D; 2(aâˆ’y)â‹…Ïƒ(z)(1âˆ’Ïƒ(z))â‹…x $$<br>$$ \frac{âˆ‚L}{âˆ‚b} &#x3D; \frac{âˆ‚L}{âˆ‚z} â‹… \frac{âˆ‚z}{âˆ‚b} &#x3D; 2(aâˆ’y)â‹…Ïƒ(z)(1âˆ’Ïƒ(z)) $$<br>$$ \frac{âˆ‚L}{âˆ‚x} &#x3D; \frac{âˆ‚L}{âˆ‚z} â‹… \frac{âˆ‚z}{âˆ‚x} &#x3D; 2(aâˆ’y)â‹…Ïƒ(z)(1âˆ’Ïƒ(z))â‹…w $$</p>
<p>PyTorch ä½¿ç”¨è‡ªåŠ¨å¾®åˆ†è¿›è¡Œåå‘ä¼ æ’­çš„ç¤ºä¾‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰è¾“å…¥ã€æƒé‡ã€åå·®å’Œç›®æ ‡</span></span><br><span class="line">x = torch.tensor([<span class="number">1.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">w = torch.tensor([<span class="number">0.5</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.tensor([<span class="number">0.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = torch.tensor([<span class="number">1.0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># å‰å‘ä¼ æ’­</span></span><br><span class="line">z = w * x + b</span><br><span class="line">a = torch.sigmoid(z)</span><br><span class="line">loss = F.mse_loss(a, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åå‘ä¼ æ’­</span></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å‡ºæ¢¯åº¦</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Gradient of x: <span class="subst">&#123;x.grad.item()&#125;</span>&quot;</span>) // x: -<span class="number">0.08872345089912415</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Gradient of w: <span class="subst">&#123;w.grad.item()&#125;</span>&quot;</span>) // w: -<span class="number">0.1774469017982483</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Gradient of b: <span class="subst">&#123;b.grad.item()&#125;</span>&quot;</span>) // b: -<span class="number">0.1774469017982483</span></span><br></pre></td></tr></table></figure></div></div></div>

<h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><h3 id="å‘é‡åŒ–ï¼ˆVectorizationï¼‰"><a href="#å‘é‡åŒ–ï¼ˆVectorizationï¼‰" class="headerlink" title="å‘é‡åŒ–ï¼ˆVectorizationï¼‰"></a>å‘é‡åŒ–ï¼ˆVectorizationï¼‰</h3><ul>
<li>Numpy ä½¿ç”¨äº†é«˜åº¦ä¼˜åŒ–çš„åº•å±‚åº“ï¼ˆå¦‚ BLAS æˆ– cuBLASï¼‰ï¼Œå…¶å†…éƒ¨å®ç°é€šå¸¸æ¯”æ‰‹åŠ¨ç¼–å†™çš„<code>for</code>å¾ªç¯è¦å¿«å¾—å¤šã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">size = <span class="number">1000000</span></span><br><span class="line">a = np.random.rand(size)</span><br><span class="line">b = np.random.rand(size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¡ç®—ç‚¹ç§¯</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">c1 = np.dot(a, b)</span><br><span class="line">np_dot_time = time.time() - start_time</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¡ç®—ç‚¹ç§¯</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">c2 = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(size):</span><br><span class="line">    c2 += a[i] * b[i]</span><br><span class="line">manual_time = time.time() - start_time</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å‡ºæ‰§è¡Œæ—¶é—´</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;c1&#125;</span> np.dot execution time: <span class="subst">&#123;np_dot_time:<span class="number">.6</span>f&#125;</span> seconds&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;c2&#125;</span> For loop execution time: <span class="subst">&#123;manual_time:<span class="number">.6</span>f&#125;</span> seconds&quot;</span>)</span><br><span class="line"><span class="comment"># 250253.55343551846 np.dot execution time: 0.000957 seconds</span></span><br><span class="line"><span class="comment"># 250253.5534355264 For loop execution time: 0.288324 seconds</span></span><br></pre></td></tr></table></figure>

<h3 id="å¹¿æ’­ï¼ˆbroadcastingï¼‰"><a href="#å¹¿æ’­ï¼ˆbroadcastingï¼‰" class="headerlink" title="å¹¿æ’­ï¼ˆbroadcastingï¼‰"></a>å¹¿æ’­ï¼ˆbroadcastingï¼‰</h3><p>NumPy çš„å¹¿æ’­æœºåˆ¶ï¼ˆbroadcastingï¼‰æ˜¯ä¸€ä¸ªå¼ºå¤§çš„åŠŸèƒ½ï¼Œå®ƒå…è®¸ä¸åŒå½¢çŠ¶çš„æ•°ç»„åœ¨ä¸€èµ·è¿›è¡Œç®—æœ¯æ“ä½œï¼Œè€Œä¸éœ€è¦æ˜¾å¼åœ°å¤åˆ¶æ•°æ®ã€‚</p>
<p>å¹¿æ’­è§„åˆ™çš„æ ¸å¿ƒæ€æƒ³æ˜¯æ‰©å±•è¾ƒå°çš„æ•°ç»„ï¼Œä½¿å…¶å½¢çŠ¶ä¸è¾ƒå¤§çš„æ•°ç»„å…¼å®¹ã€‚å…·ä½“è§„åˆ™å¦‚ä¸‹ï¼š</p>
<ul>
<li>å¦‚æœä¸¤ä¸ªæ•°ç»„çš„ç»´åº¦æ•°ä¸ç›¸åŒï¼Œåˆ™å½¢çŠ¶è¾ƒå°çš„æ•°ç»„ä¼šåœ¨å·¦ä¾§å¡«å…… 1ï¼Œä»¥åŒ¹é…è¾ƒå¤§æ•°ç»„çš„å½¢çŠ¶ã€‚</li>
<li>å¦‚æœä¸¤ä¸ªæ•°ç»„åœ¨æŸä¸ªç»´åº¦ä¸Šçš„å¤§å°ä¸åŒï¼Œåˆ™è¯¥ç»´åº¦çš„å¤§å°ä¸º 1 çš„æ•°ç»„ä¼šè¢«æ‰©å±•ä»¥åŒ¹é…å¦ä¸€ä¸ªæ•°ç»„çš„å¤§å°ã€‚</li>
<li>å¦‚æœä¸¤ä¸ªæ•°ç»„åœ¨ä»»ä½•ç»´åº¦ä¸Šçš„å¤§å°éƒ½ä¸ç›¸åŒä¸”éƒ½ä¸ä¸º 1ï¼Œåˆ™ä¼šå¼•å‘é”™è¯¯ã€‚</li>
</ul>
<div class="tabs" id="deeplearning-numpy-broadcasting"><ul class="nav-tabs"><li class="tab active"><a href="#deeplearning-numpy-broadcasting-1">æ ‡é‡å’Œæ•°ç»„</a></li><li class="tab"><a href="#deeplearning-numpy-broadcasting-2">ä¸€ç»´æ•°ç»„å’ŒäºŒç»´æ•°ç»„</a></li><li class="tab"><a href="#deeplearning-numpy-broadcasting-3">ä¸åŒå½¢çŠ¶çš„å¤šç»´æ•°ç»„</a></li></ul><div class="tab-content"><div class="tab-pane active" id="deeplearning-numpy-broadcasting-1"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">b = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ ‡é‡ b è¢«æ‰©å±•ä¸ºä¸æ•°ç»„ a ç›¸åŒçš„å½¢çŠ¶</span></span><br><span class="line">result = a + b</span><br><span class="line"><span class="built_in">print</span>(result)  <span class="comment"># è¾“å‡º [3 4 5]</span></span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="deeplearning-numpy-broadcasting-2"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">b = np.array([[<span class="number">4</span>], [<span class="number">5</span>], [<span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ•°ç»„ a è¢«æ‰©å±•ä¸º [[1, 2, 3], [1, 2, 3], [1, 2, 3]]</span></span><br><span class="line">result = a + b</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># è¾“å‡º</span></span><br><span class="line"><span class="comment"># [[ 5  6  7]</span></span><br><span class="line"><span class="comment">#  [ 6  7  8]</span></span><br><span class="line"><span class="comment">#  [ 7  8  9]]</span></span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="deeplearning-numpy-broadcasting-3"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">b = np.array([[<span class="number">10</span>], [<span class="number">20</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ•°ç»„ b è¢«æ‰©å±•ä¸º [[10, 10, 10], [20, 20, 20]]</span></span><br><span class="line">result = a + b</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># è¾“å‡º</span></span><br><span class="line"><span class="comment"># [[11 12 13]</span></span><br><span class="line"><span class="comment">#  [24 25 26]]</span></span><br></pre></td></tr></table></figure></div></div></div>

<h1 id="æµ…å±‚ç¥ç»ç½‘ç»œï¼ˆShallow-NNï¼‰"><a href="#æµ…å±‚ç¥ç»ç½‘ç»œï¼ˆShallow-NNï¼‰" class="headerlink" title="æµ…å±‚ç¥ç»ç½‘ç»œï¼ˆShallow NNï¼‰"></a>æµ…å±‚ç¥ç»ç½‘ç»œï¼ˆShallow NNï¼‰</h1><p>æµ…å±‚ç¥ç»ç½‘ç»œï¼ˆShallow Neural Networkï¼‰æ˜¯æŒ‡åªæœ‰ä¸€ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œã€‚</p>
<ul>
<li>ç»“æ„ç®€å•ï¼Œé€‚ç”¨äºè¾ƒç®€å•çš„æ•°æ®é›†ï¼Œåº”ç”¨åœ¨äºŒåˆ†ç±»ã€å¤šåˆ†ç±»æˆ–å›å½’ä»»åŠ¡ã€‚</li>
</ul>
<h2 id="åŸºæœ¬ç»“æ„"><a href="#åŸºæœ¬ç»“æ„" class="headerlink" title="åŸºæœ¬ç»“æ„"></a>åŸºæœ¬ç»“æ„</h2><p><img data-src="/images/DeepLearning/shallow_neural_network.png"></p>
<ol>
<li>è¾“å…¥å±‚ï¼šè¾“å…¥å±‚æ¥å—è¾“å…¥æ•°æ®ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªè¾“å…¥ç‰¹å¾ã€‚</li>
<li>ä¸€ä¸ªéšè—å±‚ï¼šéšè—å±‚å¯¹è¾“å…¥å±‚çš„æ•°æ®è¿›è¡Œéçº¿æ€§å˜æ¢ï¼Œé€šå¸¸åŒ…å«è‹¥å¹²ä¸ªç¥ç»å…ƒï¼Œæ¯ä¸ªç¥ç»å…ƒéƒ½åº”ç”¨ä¸€ä¸ªæ¿€æ´»å‡½æ•°ã€‚</li>
<li>è¾“å‡ºå±‚ï¼šè¾“å‡ºå±‚ç”Ÿæˆæœ€ç»ˆçš„é¢„æµ‹ç»“æœï¼ŒèŠ‚ç‚¹çš„æ•°é‡å–å†³äºä»»åŠ¡ç±»å‹ï¼ˆå¦‚åˆ†ç±»ä»»åŠ¡çš„ç±»åˆ«æ•°æˆ–å›å½’ä»»åŠ¡çš„è¾“å‡ºç»´åº¦ï¼‰ã€‚</li>
</ol>
<h2 id="å·¥ä½œåŸç†"><a href="#å·¥ä½œåŸç†" class="headerlink" title="å·¥ä½œåŸç†"></a>å·¥ä½œåŸç†</h2><p>æµ…å±‚ç¥ç»ç½‘ç»œçš„è®¡ç®—æ­¥éª¤ï¼š</p>
<ol>
<li>å‰å‘ä¼ æ’­ï¼ˆForward Propagationï¼‰</li>
</ol>
<ul>
<li>è¾“å…¥æ•°æ®é€šè¿‡è¾“å…¥å±‚ä¼ é€’åˆ°éšè—å±‚ã€‚</li>
<li>éšè—å±‚å¯¹è¾“å…¥æ•°æ®åº”ç”¨åŠ æƒå’Œ<strong>æ¿€æ´»å‡½æ•°</strong>è¿›è¡Œéçº¿æ€§å˜æ¢ã€‚</li>
<li>å˜æ¢åçš„æ•°æ®ä»éšè—å±‚ä¼ é€’åˆ°è¾“å‡ºå±‚ï¼Œç”Ÿæˆé¢„æµ‹ç»“æœã€‚</li>
</ul>
<ol start="2">
<li>æŸå¤±è®¡ç®—ï¼ˆLoss Calculationï¼‰</li>
</ol>
<ul>
<li>ä½¿ç”¨æŸå¤±å‡½æ•°è®¡ç®—é¢„æµ‹ç»“æœä¸çœŸå®å€¼ä¹‹é—´çš„è¯¯å·®ã€‚</li>
</ul>
<ol start="3">
<li>åå‘ä¼ æ’­ï¼ˆBackward Propagationï¼‰</li>
</ol>
<ul>
<li>è®¡ç®—æŸå¤±ç›¸å¯¹äºæ¯ä¸ªæƒé‡çš„æ¢¯åº¦ã€‚</li>
<li>ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç­‰ä¼˜åŒ–ç®—æ³•æ›´æ–°æƒé‡ï¼Œä»¥æœ€å°åŒ–æŸå¤±ã€‚</li>
</ul>
<h3 id="æ¿€æ´»å‡½æ•°ï¼ˆActivate-Functionï¼‰"><a href="#æ¿€æ´»å‡½æ•°ï¼ˆActivate-Functionï¼‰" class="headerlink" title="æ¿€æ´»å‡½æ•°ï¼ˆActivate Functionï¼‰"></a>æ¿€æ´»å‡½æ•°ï¼ˆActivate Functionï¼‰</h3><p>ç¥ç»ç½‘ç»œä¸­çš„æ¿€æ´»å‡½æ•°æœ‰å¤šç§ï¼Œæ¯ç§éƒ½æœ‰å…¶ç‹¬ç‰¹çš„æ€§è´¨å’Œé€‚ç”¨åœºæ™¯ã€‚</p>
<ul>
<li><code>Sigmoid</code> å‡½æ•°ï¼š$ \sigma(x) &#x3D; \frac{1}{1 + e^{-x}} $<ul>
<li>è¾“å‡ºèŒƒå›´åœ¨ (0, 1) ä¹‹é—´ã€‚</li>
<li>å¸¸ç”¨äºè¾“å‡ºå±‚è¿›è¡ŒäºŒåˆ†ç±»é—®é¢˜ã€‚</li>
<li>ç¼ºç‚¹æ˜¯å®¹æ˜“å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå› ä¸ºåœ¨æç«¯åŒºåŸŸï¼ˆå¾ˆå¤§çš„æ­£å€¼æˆ–è´Ÿå€¼ï¼‰æ¢¯åº¦è¶‹è¿‘äº0ã€‚<br><img data-src="/images/DeepLearning/activate_sigmoid.png"></li>
</ul>
</li>
<li><code>Tanh</code> åŒæ›²æ­£åˆ‡å‡½æ•°ï¼š$ \tanh(x) &#x3D; \frac{e^x - e^{-x}}{e^x + e^{-x}} $<ul>
<li>è¾“å‡ºèŒƒå›´åœ¨ (-1, 1) ä¹‹é—´ã€‚</li>
<li>ç›¸å¯¹äº <code>Sigmoid</code>ï¼Œåœ¨é›¶ç‚¹é™„è¿‘çš„æ¢¯åº¦è¾ƒå¤§ï¼Œæ”¶æ•›é€Ÿåº¦æ›´å¿«ã€‚</li>
<li>ä»ç„¶å¯èƒ½å‡ºç°æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½†ç¨‹åº¦è¾ƒ <code>Sigmoid</code> å‡½æ•°å°ã€‚<br><img data-src="/images/DeepLearning/activate_tanh.png"></li>
</ul>
</li>
<li><code>ReLU</code> (Rectified Linear Unit) å‡½æ•°ï¼š$ \text{ReLU}(x) &#x3D; \max(0, x) $<ul>
<li>éçº¿æ€§ä¸”è®¡ç®—ç®€å•ã€‚</li>
<li>åœ¨æ­£åŠè½´ä¸Šï¼Œæ¢¯åº¦ä¸ä¼šæ¶ˆå¤±ï¼Œæœ‰åˆ©äºç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</li>
<li>ç¼ºç‚¹æ˜¯æœ‰å¯èƒ½å¯¼è‡´â€œç¥ç»å…ƒæ­»äº¡â€ï¼ˆæ­»åŒºï¼‰ï¼Œå³æŸäº›ç¥ç»å…ƒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½ä¸€ç›´è¾“å‡ºä¸ºé›¶ã€‚<br><img data-src="/images/DeepLearning/activate_relu.png"></li>
</ul>
</li>
<li><code>Leaky ReLU</code> å‡½æ•°: $ \text{Leaky ReLU}(x) &#x3D; \begin{cases}<br>x &amp; \text{if } x &gt; 0 \\<br>\alpha x &amp; \text{if } x \leq 0<br>\end{cases} $<ul>
<li>è§£å†³äº† ReLU çš„æ­»åŒºé—®é¢˜ï¼Œé€šè¿‡åœ¨è´ŸåŠè½´å¼•å…¥ä¸€ä¸ªå¾ˆå°çš„æ–œç‡ï¼ˆ$ğ›¼$ï¼‰ã€‚</li>
<li>è¾“å‡ºèŒƒå›´ä¸º $(-âˆ, +âˆ)$ã€‚<br><img data-src="/images/DeepLearning/activate_leakyrelu.png"></li>
</ul>
</li>
<li><code>ELU</code> (Exponential Linear Unit) å‡½æ•°ï¼š$ \text{ELU}(x) &#x3D; \begin{cases}<br>x &amp; \text{if } x &gt; 0 \\<br>\alpha(e^x - 1) &amp; \text{if } x \leq 0<br>\end{cases} $<ul>
<li>è´ŸåŠè½´éƒ¨åˆ†å¹³æ»‘ä¸”éé›¶ï¼Œæœ‰åŠ©äºé˜²æ­¢ç¥ç»å…ƒæ­»äº¡ã€‚</li>
<li>åœ¨è´ŸåŠè½´çš„è¾“å‡ºæœ‰ä¸€å®šèŒƒå›´ï¼Œç¼“è§£äº†æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</li>
<li>ç›¸å¯¹äº Leaky ReLUï¼Œæ›´åŠ å¹³æ»‘ï¼Œè®­ç»ƒé€Ÿåº¦è¾ƒå¿«ã€‚<br><img data-src="/images/DeepLearning/activate_elu.png"></li>
</ul>
</li>
<li><code>Softmax</code> å‡½æ•°ï¼š$ \text{softmax}(x_i) &#x3D; \frac{e^{x_i}}{\sum_{j&#x3D;1}^{n} e^{x_j}} $<ul>
<li>å¸¸ç”¨äºå¤šåˆ†ç±»é—®é¢˜çš„è¾“å‡ºå±‚ï¼Œå¯ä»¥å°†ä¸€ä¸ªåŒ…å«å®æ•°çš„å‘é‡è½¬æ¢ä¸ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒå‘é‡ã€‚</li>
<li>å°†è¾“å…¥è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œè¾“å‡ºçš„å„å€¼åœ¨ $(0, 1)$ ä¹‹é—´ï¼Œæ€»å’Œä¸º 1ã€‚<br><img data-src="/images/DeepLearning/activate_softmax.png"></li>
</ul>
</li>
</ul>
<p><strong>é€‰æ‹©æ¿€æ´»å‡½æ•°çš„è€ƒè™‘å› ç´ </strong></p>
<ul>
<li>æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼šSigmoid å’Œ Tanh åœ¨æç«¯åŒºåŸŸçš„æ¢¯åº¦è¶‹è¿‘äº 0ï¼Œå®¹æ˜“å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ã€‚ReLU å’Œå…¶å˜ç§å¦‚ Leaky ReLUã€ELU åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äº†è¿™ä¸€é—®é¢˜ã€‚</li>
<li>éçº¿æ€§ï¼šæ¿€æ´»å‡½æ•°çš„éçº¿æ€§ç‰¹æ€§ä½¿å¾—ç¥ç»ç½‘ç»œå¯ä»¥æ‹Ÿåˆå¤æ‚çš„å‡½æ•°ã€‚</li>
<li>è®¡ç®—æˆæœ¬ï¼šReLU è®¡ç®—ç®€å•ï¼Œå¸¸ç”¨äºæ·±å±‚ç½‘ç»œçš„éšè—å±‚ã€‚ELU å’Œ Leaky ReLU çš„è®¡ç®—å¤æ‚åº¦ç•¥é«˜ï¼Œä½†æœ‰æ—¶èƒ½æä¾›æ›´å¥½çš„æ€§èƒ½ã€‚</li>
<li>è¾“å‡ºèŒƒå›´ï¼šæ ¹æ®ä»»åŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„è¾“å‡ºèŒƒå›´ã€‚å¦‚äºŒåˆ†ç±»é—®é¢˜å¸¸ç”¨ Sigmoidï¼Œå¤šåˆ†ç±»é—®é¢˜ç”¨ Softmaxã€‚</li>
</ul>
<p><strong>å®é™…åº”ç”¨</strong></p>
<ul>
<li>éšè—å±‚ï¼šReLU å’Œå…¶å˜ç§ï¼ˆLeaky ReLUã€ELUï¼‰è¾ƒä¸ºå¸¸ç”¨ã€‚</li>
<li>è¾“å‡ºå±‚ï¼šäºŒåˆ†ç±»é—®é¢˜å¸¸ç”¨ Sigmoidï¼Œå¤šåˆ†ç±»é—®é¢˜å¸¸ç”¨ Softmaxï¼Œå›å½’é—®é¢˜å¸¸ç”¨çº¿æ€§æ¿€æ´»å‡½æ•°ã€‚</li>
</ul>
<h2 id="åˆå§‹åŒ–å‚æ•°"><a href="#åˆå§‹åŒ–å‚æ•°" class="headerlink" title="åˆå§‹åŒ–å‚æ•°"></a>åˆå§‹åŒ–å‚æ•°</h2><p>åœ¨ç¥ç»ç½‘ç»œçš„è®­ç»ƒä¸­ï¼Œéšæœºåˆå§‹åŒ–å‚æ•°ï¼ˆRandom Initializationï¼‰éå¸¸é‡è¦ï¼Œä¸»è¦åŸå› æ˜¯ä¸ºäº†é¿å…å¯¹ç§°é—®é¢˜å¹¶ç¡®ä¿ç½‘ç»œèƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ ã€‚</p>
<h3 id="å¯¹ç§°é—®é¢˜ï¼ˆsymmetry-breaking-problemï¼‰"><a href="#å¯¹ç§°é—®é¢˜ï¼ˆsymmetry-breaking-problemï¼‰" class="headerlink" title="å¯¹ç§°é—®é¢˜ï¼ˆsymmetry breaking problemï¼‰"></a>å¯¹ç§°é—®é¢˜ï¼ˆsymmetry breaking problemï¼‰</h3><p>å¯¹ç§°é—®é¢˜æ˜¯æŒ‡åœ¨ç¥ç»ç½‘ç»œçš„åˆå§‹åŒ–é˜¶æ®µï¼Œå¦‚æœæ‰€æœ‰æƒé‡éƒ½è®¾ç½®ä¸ºç›¸åŒçš„å€¼ï¼ˆä¾‹å¦‚é›¶ï¼‰ï¼Œé‚£ä¹ˆæ¯ä¸ªç¥ç»å…ƒåœ¨åŒä¸€å±‚ä¸­çš„è¾“å‡ºéƒ½æ˜¯ç›¸åŒçš„ã€‚è¿™ä¼šå¯¼è‡´åå‘ä¼ æ’­ä¸­çš„æ¢¯åº¦æ›´æ–°ä¹Ÿæ˜¯ç›¸åŒçš„ï¼Œä»è€Œæ— æ³•ä½¿ç½‘ç»œä¸­çš„ç¥ç»å…ƒå­¦ä¹ åˆ°ä¸åŒçš„ç‰¹å¾ã€‚è¿™ç§æƒ…å†µä¼šé˜»ç¢ç½‘ç»œçš„å­¦ä¹ èƒ½åŠ›ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½éå¸¸å·®ã€‚</p>
<p>å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œï¼Œæ¯å±‚æœ‰ä¸¤ä¸ªç¥ç»å…ƒã€‚</p>
<ul>
<li>è¾“å…¥å±‚ï¼š $ ğ‘¥ &#x3D; [ğ‘¥_1, ğ‘¥_2] $</li>
<li>éšè—å±‚ï¼š $ â„ &#x3D; [â„_1, â„_2] $<ul>
<li>$ h_1â€‹ &#x3D; f(w_1â€‹ â‹… x_1â€‹ + w_2â€‹ â‹… x_2â€‹) $</li>
<li>$ h_2â€‹ &#x3D; f(w_3â€‹ â‹… x_1â€‹ + w_4â€‹ â‹… x_2â€‹) $</li>
</ul>
</li>
</ul>
<p>è®¾åˆå§‹æƒé‡å‡ä¸ºé›¶ï¼ˆæˆ–è€…ä»»ä½•ç›¸åŒçš„å€¼ï¼‰ï¼Œç„¶åè¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ï¼š</p>
<ul>
<li>å‰å‘ä¼ æ’­ï¼š<ul>
<li>ç”±äº $ ğ‘¤_1 &#x3D; ğ‘¤_2 &#x3D; ğ‘¤_3 &#x3D; ğ‘¤_4 &#x3D; 0 $ï¼Œæ‰€ä»¥ $ â„_1 &#x3D; â„_2 &#x3D; ğ‘“(0) $</li>
</ul>
</li>
<li>åå‘ä¼ æ’­ï¼š<ul>
<li>è®¡ç®—æ¢¯åº¦æ—¶ï¼Œæ‰€æœ‰æ¢¯åº¦ä¹Ÿæ˜¯ç›¸åŒçš„ï¼Œå› ä¸ºå‰å‘ä¼ æ’­çš„è¾“å‡ºæ˜¯ç›¸åŒçš„ã€‚</li>
<li>æ›´æ–°åçš„æƒé‡ä»ç„¶ä¿æŒç›¸åŒçš„å€¼ï¼Œå¯¼è‡´æ¯æ¬¡è®­ç»ƒæ›´æ–°éƒ½ä¸€æ ·ã€‚</li>
</ul>
</li>
</ul>
<h2 id="è®¡ç®—è¿‡ç¨‹"><a href="#è®¡ç®—è¿‡ç¨‹" class="headerlink" title="è®¡ç®—è¿‡ç¨‹"></a>è®¡ç®—è¿‡ç¨‹</h2><p>å‡è®¾æœ‰ä¸€ä¸ªæµ…å±‚ç¥ç»ç½‘ç»œï¼Œå…·æœ‰ä»¥ä¸‹ç»“æ„ï¼š</p>
<ul>
<li>è¾“å…¥å±‚ï¼š3ä¸ªè¾“å…¥ç‰¹å¾ $ğ‘¥_1, ğ‘¥_2, ğ‘¥_3$</li>
<li>éšè—å±‚ï¼š2ä¸ªç¥ç»å…ƒ</li>
<li>è¾“å‡ºå±‚ï¼š1ä¸ªç¥ç»å…ƒ<br>æ¯ä¸ªéšè—å±‚çš„ç¥ç»å…ƒå’Œè¾“å‡ºå±‚çš„ç¥ç»å…ƒéƒ½å¸¦æœ‰æƒé‡å’Œåå·®ã€‚æ¿€æ´»å‡½æ•°å‡è®¾ä¸ºReLUï¼ˆRectified Linear Unitï¼‰ã€‚</li>
</ul>
<p>é‚£ä¹ˆï¼Œæ•°å­¦è¡¨ç¤ºä¸ºï¼š</p>
<ol>
<li>è¾“å…¥å±‚åˆ°éšè—å±‚ï¼š</li>
</ol>
<ul>
<li>ç¬¬ä¸€ä¸ªéšè—å±‚ç¥ç»å…ƒçš„è¾“å‡ºï¼š$ h_1â€‹ &#x3D; Ïƒ(w_{11}â€‹ x_1â€‹ + w_{12}â€‹ x_2â€‹ + w_{13}â€‹ x_3â€‹ + b_1) $</li>
<li>ç¬¬äºŒä¸ªéšè—å±‚ç¥ç»å…ƒçš„è¾“å‡ºï¼š$ h_2â€‹ &#x3D; Ïƒ(w_{21}â€‹ x_1â€‹ + w_{22}â€‹ x_2â€‹ + w_{23}â€‹ x_3â€‹ + b_2) $</li>
<li>$ğœ$ è¡¨ç¤ºæ¿€æ´»å‡½æ•° <code>ReLU</code>ï¼Œå³ $ğœ(ğ‘§) &#x3D; maxâ¡(0, ğ‘§)$</li>
</ul>
<ol start="2">
<li>éšè—å±‚åˆ°è¾“å‡ºå±‚ï¼š</li>
</ol>
<ul>
<li>è¾“å‡ºå±‚ç¥ç»å…ƒçš„è¾“å‡ºï¼š$ yâ€‹ &#x3D; w_{31}â€‹ h_1â€‹ + w_{32}â€‹ h_2â€‹â€‹ + b_3 $</li>
</ul>
<p><img data-src="/images/DeepLearning/shallow_neural_network_sample.jpg"></p>
<div class="tabs" id="deeplearning-shallownn-sample"><ul class="nav-tabs"><li class="tab active"><a href="#deeplearning-shallownn-sample-1">è®¡ç®—æ­¥éª¤</a></li><li class="tab"><a href="#deeplearning-shallownn-sample-2">çŸ©é˜µè¿ç®—</a></li><li class="tab"><a href="#deeplearning-shallownn-sample-3">PyTorch</a></li></ul><div class="tab-content"><div class="tab-pane active" id="deeplearning-shallownn-sample-1"><ol>
<li>è¾“å…¥å±‚åˆ°éšè—å±‚çš„è®¡ç®—<br><strong>è¾“å…¥ç‰¹å¾å‘é‡ï¼š</strong><br>$$ \mathbf{X} &#x3D; \begin{bmatrix}<br>x_1 \\<br>x_2 \\<br>x_3<br>\end{bmatrix} $$<br><strong>éšè—å±‚çš„æƒé‡çŸ©é˜µå’Œåå·®å‘é‡ï¼š</strong><br>$$<br>\mathbf{W}^{(1)} &#x3D; \begin{bmatrix}<br>w_{11} &amp; w_{12} &amp; w_{13} \\<br>w_{21} &amp; w_{22} &amp; w_{23}<br>\end{bmatrix}<br>$$<br>$$<br>\mathbf{b}^{(1)} &#x3D; \begin{bmatrix}<br>b_1 \\<br>b_2<br>\end{bmatrix}<br>$$<br><strong>éšè—å±‚çš„çº¿æ€§ç»„åˆè¾“å‡ºï¼š</strong><br>$$<br>\mathbf{Z}^{(1)} &#x3D; \mathbf{W}^{(1)} \mathbf{X} + \mathbf{b}^{(1)} &#x3D;<br>\begin{bmatrix}<br>w_{11} &amp; w_{12} &amp; w_{13} \\<br>w_{21} &amp; w_{22} &amp; w_{23}<br>\end{bmatrix}<br>\begin{bmatrix}<br>x_1 \\<br>x_2 \\<br>x_3<br>\end{bmatrix}<br>\text{+}<br>\begin{bmatrix}<br>b_1 \\<br>b_2<br>\end{bmatrix}<br>$$<br><strong>åº”ç”¨æ¿€æ´»å‡½æ•°ï¼ˆReLUï¼‰åçš„éšè—å±‚è¾“å‡ºï¼š</strong><br>$$<br>\mathbf{h}^{(1)} &#x3D; \sigma(\mathbf{Z}^{(1)}) &#x3D; \begin{bmatrix}<br>\sigma(z_1^{(1)}) \\<br>\sigma(z_2^{(1)})<br>\end{bmatrix}<br>$$<br>å…¶ä¸­ï¼Œå³ $ğœ(ğ‘§) &#x3D; maxâ¡(0, ğ‘§)$ æ˜¯<code>ReLU</code>æ¿€æ´»å‡½æ•°ã€‚</li>
<li>éšè—å±‚åˆ°è¾“å‡ºå±‚çš„è®¡ç®—<br><strong>è¾“å‡ºå±‚çš„æƒé‡å‘é‡å’Œåå·®æ ‡é‡ï¼š</strong><br>$$<br>\mathbf{W}^{(2)} &#x3D; \begin{bmatrix}<br>w_{31} &amp; w_{32}<br>\end{bmatrix}<br>$$<br>$$<br>b^{(2)} &#x3D; b_3<br>$$<br><strong>è¾“å‡ºå±‚çš„çº¿æ€§ç»„åˆè¾“å‡ºï¼š</strong><br>$$<br>Z^{(2)} &#x3D; \mathbf{W}^{(2)} \mathbf{h}^{(1)} + b^{(2)} &#x3D;<br>\begin{bmatrix}<br>w_{31} &amp; w_{32}<br>\end{bmatrix}<br>\begin{bmatrix}<br>\sigma(z_1^{(1)}) \\<br>\sigma(z_2^{(1)})<br>\end{bmatrix}<br>\text{+} b_3<br>$$<br>ç”±äºè¾“å‡ºå±‚çš„è¾“å‡ºæ˜¯çº¿æ€§æ¿€æ´»ï¼Œå› æ­¤æœ€ç»ˆè¾“å‡ºä¸ºï¼š<br>$$<br>y &#x3D; Z^{(2)}<br>$$</li>
</ol></div><div class="tab-pane" id="deeplearning-shallownn-sample-2"><p><strong>è¾“å…¥ç‰¹å¾å‘é‡ï¼š</strong><br>$$ \mathbf{X} &#x3D; \begin{bmatrix}<br>1.0 \\<br>2.0 \\<br>3.0<br>\end{bmatrix} $$<br><strong>å‡è®¾ä»¥ä¸‹æƒé‡å’Œåå·®ï¼š</strong><br>$$ \mathbf{W}^{(1)} &#x3D; \begin{bmatrix}<br>0.2 &amp; 0.4 &amp; 0.6 \\<br>0.8 &amp; 0.1 &amp; 0.3<br>\end{bmatrix},<br>\mathbf{b}^{(1)} &#x3D; \begin{bmatrix}<br>0.1 \\<br>0.2<br>\end{bmatrix} $$<br>$$ \mathbf{W}^{(2)} &#x3D; \begin{bmatrix}<br>0.5 &amp; 0.7<br>\end{bmatrix},<br>\mathbf{b}^{(2)} &#x3D; \begin{bmatrix}<br>0.3<br>\end{bmatrix} $$<br><strong>è®¡ç®—è¿‡ç¨‹ï¼š</strong></p>
<ol>
<li>ç¬¬ä¸€å±‚ï¼ˆéšè—å±‚ï¼‰çº¿æ€§ç»„åˆï¼ˆçŸ©é˜µä¹˜æ³•åŠ ä¸Šåå·®ï¼‰<br>$$ \mathbf{Z}^{(1)} &#x3D; \mathbf{W}^{(1)} \mathbf{X} + \mathbf{b}^{(1)} &#x3D; \begin{bmatrix}<br>0.2 &amp; 0.4 &amp; 0.6 \\<br>0.8 &amp; 0.1 &amp; 0.3<br>\end{bmatrix}<br>\begin{bmatrix}<br>1.0 \\<br>2.0 \\<br>3.0<br>\end{bmatrix}<br>\text{+}<br>\begin{bmatrix}<br>0.1 \\<br>0.2<br>\end{bmatrix} $$<br>$$ \mathbf{Z}^{(1)} &#x3D; \begin{bmatrix}<br>0.2 \times 1 + 0.4 \times 2 + 0.6 \times 3 + 0.1 \\<br>0.8 \times 1 + 0.1 \times 2 + 0.3 \times 3 + 0.2<br>\end{bmatrix}<br>&#x3D; \begin{bmatrix}<br>2.9 \\<br>2.1<br>\end{bmatrix} $$</li>
<li>ç¬¬ä¸€å±‚ï¼ˆéšè—å±‚ï¼‰æ¿€æ´»å‡½æ•° (ReLU)ï¼š<br>$$ \mathbf{h}^{(1)} &#x3D; \sigma(\mathbf{Z}^{(1)}) &#x3D; \begin{bmatrix}<br>max(0, 2.9) \\<br>max(0, 2.1)<br>\end{bmatrix} &#x3D; \begin{bmatrix}<br>2.9 \\<br>2.1<br>\end{bmatrix} $$</li>
<li>ç¬¬äºŒå±‚ï¼ˆè¾“å‡ºå±‚ï¼‰çº¿æ€§ç»„åˆï¼š<br>$$ Z^{(2)} &#x3D; \mathbf{W}^{(2)} \mathbf{h}^{(1)} + b^{(2)} &#x3D; \begin{bmatrix}<br>0.5 &amp; 0.7<br>\end{bmatrix}<br>\begin{bmatrix}<br>2.9 \\<br>2.1<br>\end{bmatrix}<br>\text{+}<br>\begin{bmatrix}<br>0.3<br>\end{bmatrix}<br>&#x3D; 0.5 \times 2.9 + 0.7 \times 2.1 + 0.3<br>&#x3D; 3.22 $$<br>å› æ­¤ï¼Œæœ€ç»ˆè¾“å‡º $ğ‘¦ &#x3D; Z^{(2)} &#x3D; 3.22 $ã€‚</li>
</ol></div><div class="tab-pane" id="deeplearning-shallownn-sample-3"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å…¥å‘é‡</span></span><br><span class="line">X = torch.tensor([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬ä¸€å±‚çš„æƒé‡å’Œåå·®</span></span><br><span class="line">W1 = torch.tensor([[<span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.6</span>],</span><br><span class="line">                   [<span class="number">0.8</span>, <span class="number">0.1</span>, <span class="number">0.3</span>]])</span><br><span class="line">b1 = torch.tensor([<span class="number">0.1</span>, <span class="number">0.2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬äºŒå±‚çš„æƒé‡å’Œåå·®</span></span><br><span class="line">W2 = torch.tensor([<span class="number">0.5</span>, <span class="number">0.7</span>])</span><br><span class="line">b2 = torch.tensor(<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬ä¸€å±‚çº¿æ€§ç»„åˆ</span></span><br><span class="line">Z1 = torch.matmul(W1, X) + b1</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Z1:&quot;</span>, Z1) <span class="comment"># Z1: tensor([2.9000, 2.1000])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬ä¸€å±‚æ¿€æ´»å‡½æ•° (ReLU)</span></span><br><span class="line">h1 = F.relu(Z1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;h1:&quot;</span>, h1) <span class="comment"># h1: tensor([2.9000, 2.1000])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬äºŒå±‚çº¿æ€§ç»„åˆ</span></span><br><span class="line">Z2 = torch.matmul(W2, h1) + b2</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Z2:&quot;</span>, Z2) <span class="comment"># Z2: tensor(3.2200)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æœ€ç»ˆè¾“å‡º</span></span><br><span class="line">y = Z2.item()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Output y:&quot;</span>, y) <span class="comment"># Output y: 3.2200000286102295</span></span><br></pre></td></tr></table></figure></div></div></div>

<h2 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h2><p>å‡è®¾ä¸€ä¸ªç®€å•çš„æµ…å±‚ç¥ç»ç½‘ç»œï¼Œè¾“å…¥å±‚æœ‰ $ğ‘›$ ä¸ªç‰¹å¾ï¼Œéšè—å±‚æœ‰ $ğ‘š$ ä¸ªç¥ç»å…ƒï¼Œè¾“å‡ºå±‚æœ‰ $ğ‘˜$ ä¸ªç¥ç»å…ƒã€‚</p>
<ol>
<li>è¾“å…¥å±‚åˆ°éšè—å±‚ï¼š</li>
</ol>
<ul>
<li>è¾“å…¥ $ğ‘¥$ æ˜¯ä¸€ä¸ª $ğ‘›-ç»´å‘é‡$ã€‚</li>
<li>æƒé‡çŸ©é˜µ $ğ‘Š_1$â€‹ å½¢çŠ¶ä¸º $ğ‘šÃ—ğ‘›$ï¼Œåå·®å‘é‡ $ğ‘_1$â€‹ å½¢çŠ¶ä¸º $ğ‘š$ã€‚</li>
<li>éšè—å±‚çš„è¾“å‡º $â„$ é€šè¿‡æ¿€æ´»å‡½æ•° $ğœ$ è®¡ç®—ï¼š<br>  $$ â„ &#x3D; ğœ(ğ‘Š_1ğ‘¥ + ğ‘_1) $$</li>
</ul>
<ol start="2">
<li>éšè—å±‚åˆ°è¾“å‡ºå±‚ï¼š</li>
</ol>
<ul>
<li>æƒé‡çŸ©é˜µ $ğ‘Š_2$ å½¢çŠ¶ä¸º $ğ‘˜$ï¼ˆå‡è®¾å•è¾“å‡ºï¼‰ï¼Œåå·®å‘é‡ $ğ‘_2$ å½¢çŠ¶ä¸º $ğ‘˜$ã€‚</li>
<li>è¾“å‡ºå±‚çš„è¾“å‡º $ğ‘¦$ï¼š<br>  $$ ğ‘¦ &#x3D; ğ‘Š_2â„ + ğ‘_2 $$</li>
</ul>
<p>ç¤ºä¾‹ä»£ç ï¼š</p>
<p>ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨ Python å’Œ TensorFlow æ„å»ºæµ…å±‚ç¥ç»ç½‘ç»œçš„ç¤ºä¾‹ä»£ç ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ„å»ºæµ…å±‚ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ˆæŒ‰é¡ºåºå †å å„å±‚çš„é¡ºåºæ¨¡å‹ï¼‰</span></span><br><span class="line">model = Sequential([</span><br><span class="line">    Dense(<span class="number">10</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">3</span>,)),  <span class="comment"># éšè—å±‚ï¼Œ10ä¸ªç¥ç»å…ƒï¼Œè¾“å…¥ç»´åº¦ä¸º3ï¼ŒReLUæ¿€æ´»å‡½æ•°</span></span><br><span class="line">    Dense(<span class="number">1</span>)  <span class="comment"># è¾“å‡ºå±‚ï¼Œ1ä¸ªç¥ç»å…ƒï¼ˆå›å½’ä»»åŠ¡ï¼‰ï¼Œç”¨äºè¾“å‡ºä¸€ä¸ªæ ‡é‡å€¼ï¼Œæ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼ˆé»˜è®¤æ˜¯çº¿æ€§æ¿€æ´»ï¼‰</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¼–è¯‘æ¨¡å‹ï¼ˆAdamä¼˜åŒ–å™¨æ›´æ–°æ¨¡å‹çš„æƒé‡ï¼›å‡æ–¹è¯¯å·®ä½œä¸ºæŸå¤±å‡½æ•°ï¼‰</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;mean_squared_error&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å‡è®¾æœ‰ä¸€äº›è®­ç»ƒæ•°æ®</span></span><br><span class="line">X_train = np.random.rand(<span class="number">100</span>, <span class="number">3</span>)  <span class="comment"># ç”Ÿæˆ100ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«3ä¸ªç‰¹å¾</span></span><br><span class="line">y_train = np.random.rand(<span class="number">100</span>, <span class="number">1</span>)  <span class="comment"># ç”Ÿæˆ100ä¸ªç›®æ ‡å€¼</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨è®­ç»ƒæ•°æ®ï¼Œè®­ç»ƒ10ä¸ªå‘¨æœŸï¼‰</span></span><br><span class="line">model.fit(X_train, y_train, epochs=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹</span></span><br><span class="line">X_test = np.random.rand(<span class="number">10</span>, <span class="number">3</span>)  <span class="comment"># ç”Ÿæˆ10ä¸ªæ–°çš„æµ‹è¯•æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«3ä¸ªç‰¹å¾</span></span><br><span class="line">predictions = model.predict(X_test) <span class="comment"># ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æµ‹è¯•æ ·æœ¬è¿›è¡Œé¢„æµ‹ï¼Œå¾—åˆ°æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹å€¼</span></span><br><span class="line"><span class="built_in">print</span>(predictions) <span class="comment"># æ¯ä¸ªç»“æœå¯¹åº”ä¸€ä¸ªæµ‹è¯•æ ·æœ¬ã€‚æ¯ä¸ªé¢„æµ‹å€¼æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œè¡¨ç¤ºæ¨¡å‹å¯¹è¾“å…¥ç‰¹å¾ç»„åˆçš„é¢„æµ‹è¾“å‡º</span></span><br><span class="line"><span class="comment"># [[0.292369  ]</span></span><br><span class="line"><span class="comment">#  [0.5589997 ]</span></span><br><span class="line"><span class="comment">#  [0.53765506]</span></span><br><span class="line"><span class="comment">#  [0.4641093 ]</span></span><br><span class="line"><span class="comment">#  [0.40080714]</span></span><br><span class="line"><span class="comment">#  [0.5647431 ]</span></span><br><span class="line"><span class="comment">#  [0.5349394 ]</span></span><br><span class="line"><span class="comment">#  [0.5442955 ]</span></span><br><span class="line"><span class="comment">#  [0.40377063]</span></span><br><span class="line"><span class="comment">#  [0.40167415]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># éªŒè¯æ¨¡å‹ç»“æœ</span></span><br><span class="line">y_test = np.random.rand(<span class="number">10</span>, <span class="number">1</span>)  <span class="comment"># å‡è®¾æœ‰çœŸå®çš„ç›®æ ‡å€¼</span></span><br><span class="line">mse = mean_squared_error(y_test, predictions) <span class="comment"># ä½¿ç”¨å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æ¥è¡¡é‡é¢„æµ‹æ€§èƒ½</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Mean Squared Error: <span class="subst">&#123;mse&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># Mean Squared Error: 0.4814553488417099</span></span><br></pre></td></tr></table></figure>

<h1 id="æ·±å±‚ç¥ç»ç½‘ç»œï¼ˆDeep-NNï¼‰"><a href="#æ·±å±‚ç¥ç»ç½‘ç»œï¼ˆDeep-NNï¼‰" class="headerlink" title="æ·±å±‚ç¥ç»ç½‘ç»œï¼ˆDeep NNï¼‰"></a>æ·±å±‚ç¥ç»ç½‘ç»œï¼ˆDeep NNï¼‰</h1><p>æ·±å±‚ç¥ç»ç½‘ç»œï¼ˆDeep Neural Networks, DNNï¼‰æ˜¯åŒ…å«å¤šä¸ªéšè—å±‚ï¼ˆæ·±åº¦é€šå¸¸è¶…è¿‡ä¸‰å±‚ï¼‰çš„ç¥ç»ç½‘ç»œã€‚</p>
<p><img data-src="/images/DeepLearning/deep_neural_network.png"></p>
<p>ç¥ç»ç½‘ç»œçš„å±‚æ•°æ˜¯è¿™ä¹ˆå®šä¹‰çš„ï¼š</p>
<ul>
<li>ä»å·¦åˆ°å³ï¼Œç”± 0 å¼€å§‹å®šä¹‰ï¼Œæ¯”å¦‚ä¸Šå›¾ï¼Œ $ [ğ‘¥_1, ğ‘¥_2, ğ‘¥_3]$ æ˜¯ç¬¬ 0 å±‚ï¼Œè¿™å±‚å·¦è¾¹çš„éšè—å±‚æ˜¯ç¬¬ 1 å±‚ï¼Œç”±æ­¤ç±»æ¨ã€‚</li>
<li>å½“è®¡ç®—ç¥ç»ç½‘ç»œçš„å±‚æ•°æ—¶ï¼Œé€šå¸¸å¿½ç•¥è¾“å…¥å±‚ï¼Œåªç®—éšè—å±‚å’Œè¾“å‡ºå±‚ã€‚</li>
</ul>
<h2 id="è¶…å‚æ•°ï¼ˆhyperparametersï¼‰"><a href="#è¶…å‚æ•°ï¼ˆhyperparametersï¼‰" class="headerlink" title="è¶…å‚æ•°ï¼ˆhyperparametersï¼‰"></a>è¶…å‚æ•°ï¼ˆhyperparametersï¼‰</h2><p>è¶…å‚æ•°ï¼ˆhyperparametersï¼‰æ˜¯æŒ‡åœ¨æ¨¡å‹è®­ç»ƒä¹‹å‰éœ€è¦è®¾ç½®çš„å‚æ•°ï¼Œè¿™äº›å‚æ•°ä¸ä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´æ–°ï¼Œä½†ä¼šæ˜¾è‘—å½±å“æ¨¡å‹çš„æ€§èƒ½å’Œè®­ç»ƒæ•ˆæœã€‚</p>
<ul>
<li>é¢„å¤„ç†æ–¹æ³•ï¼ˆPreprocessing Methodsï¼‰ï¼šåŒ…æ‹¬æ•°æ®æ ‡å‡†åŒ–ã€å½’ä¸€åŒ–ã€æ•°æ®å¢å¼ºç­‰ã€‚<ul>
<li>è‰¯å¥½çš„æ•°æ®é¢„å¤„ç†èƒ½å¤ŸåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œæé«˜æ¨¡å‹çš„æ€§èƒ½å’Œç¨³å®šæ€§ã€‚</li>
</ul>
</li>
<li>ç½‘ç»œç»“æ„ï¼ˆNetwork Architectureï¼‰ï¼šåŒ…æ‹¬å±‚æ•°ã€æ¯å±‚çš„ç¥ç»å…ƒæ•°é‡ã€æ¿€æ´»å‡½æ•°ç±»å‹ç­‰ã€‚<ul>
<li>ä¸åŒçš„ç½‘ç»œç»“æ„èƒ½å¤Ÿæ•æ‰åˆ°ä¸åŒå±‚æ¬¡çš„ç‰¹å¾ï¼Œé€‚åº”ä¸åŒå¤æ‚åº¦çš„ä»»åŠ¡ã€‚</li>
</ul>
</li>
<li>æ‰¹å¤§å°ï¼ˆBatch Sizeï¼‰ï¼šæŒ‡çš„æ˜¯æ¯æ¬¡å‚æ•°æ›´æ–°æ—¶ä½¿ç”¨çš„è®­ç»ƒæ ·æœ¬çš„æ•°é‡ã€‚<ul>
<li>è¾ƒå°çš„æ‰¹å¤§å°å¯ä»¥å¸¦æ¥æ›´å¤šçš„æ›´æ–°æ¬¡æ•°ï¼Œå¯èƒ½æ›´å¿«åœ°æ”¶æ•›ï¼Œä½†æ¯æ¬¡æ›´æ–°çš„æ³¢åŠ¨è¾ƒå¤§ã€‚</li>
<li>è¾ƒå¤§çš„æ‰¹å¤§å°å¯ä»¥æ›´ç¨³å®šåœ°æ›´æ–°æƒé‡ï¼Œä½†æ¯æ¬¡æ›´æ–°çš„è®¡ç®—é‡è¾ƒå¤§ï¼Œè®­ç»ƒé€Ÿåº¦å¯èƒ½ä¼šå˜æ…¢ã€‚</li>
</ul>
</li>
<li>å­¦ä¹ ç‡ï¼ˆLearning Rateï¼‰ï¼šå†³å®šäº†æ¯æ¬¡å‚æ•°æ›´æ–°çš„æ­¥é•¿å¤§å°ã€‚åœ¨æ¢¯åº¦ä¸‹é™ç®—æ³•ä¸­ï¼Œå®ƒæ˜¯ç”¨æ¥è°ƒæ•´æ¯ä¸ªæƒé‡çš„å˜åŒ–å¹…åº¦çš„ç³»æ•°ã€‚<ul>
<li>å­¦ä¹ ç‡è¿‡å¤§å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éœ‡è¡æˆ–å‘æ•£ã€‚</li>
<li>å­¦ä¹ ç‡è¿‡å°åˆ™ä¼šä½¿è®­ç»ƒè¿‡ç¨‹å˜å¾—éå¸¸ç¼“æ…¢ï¼Œç”šè‡³å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚</li>
</ul>
</li>
<li>ä¼˜åŒ–ç®—æ³•ï¼ˆOptimization Algorithmï¼‰ï¼šå†³å®šäº†å¦‚ä½•æ ¹æ®æŸå¤±å‡½æ•°æ›´æ–°æ¨¡å‹çš„å‚æ•°ã€‚<ul>
<li>é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–ç®—æ³•å¯ä»¥åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œæé«˜æ¨¡å‹çš„æ”¶æ•›æ•ˆæœã€‚</li>
</ul>
</li>
<li>è¿­ä»£æ¬¡æ•°ï¼ˆNumber of Epochsï¼‰ï¼šæŒ‡æ•´ä¸ªè®­ç»ƒæ•°æ®é›†è¢«å®Œæ•´è®­ç»ƒçš„æ¬¡æ•°ã€‚<ul>
<li>è¿­ä»£æ¬¡æ•°è¿‡å°‘å¯èƒ½å¯¼è‡´æ¬ æ‹Ÿåˆï¼Œè¿­ä»£æ¬¡æ•°è¿‡å¤šå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆã€‚é€šå¸¸éœ€è¦é€šè¿‡éªŒè¯é›†æ¥é€‰æ‹©åˆé€‚çš„è¿­ä»£æ¬¡æ•°ã€‚</li>
</ul>
</li>
<li>æ­£åˆ™åŒ–å‚æ•°ï¼ˆRegularization Parametersï¼‰ï¼šæœ‰åŠ©äºæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚</li>
<li>æ¿€æ´»å‡½æ•°ï¼ˆActivation Functionï¼‰ï¼šå†³å®šäº†æ¯ä¸ªç¥ç»å…ƒçš„è¾“å‡ºå½¢å¼ã€‚<ul>
<li>é€‰æ‹©åˆé€‚çš„æ¿€æ´»å‡½æ•°å¯ä»¥æé«˜æ¨¡å‹çš„éçº¿æ€§è¡¨ç¤ºèƒ½åŠ›ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ã€‚</li>
</ul>
</li>
<li>æŸå¤±å‡½æ•°ï¼ˆLoss Functionï¼‰ï¼šæ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ã€‚<ul>
<li>é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°èƒ½å¤Ÿå‡†ç¡®åæ˜ æ¨¡å‹çš„è®­ç»ƒæ•ˆæœï¼ŒæŒ‡å¯¼å‚æ•°æ›´æ–°ã€‚</li>
</ul>
</li>
</ul>
<h2 id="æ•°æ®é›†ï¼ˆdata-setï¼‰"><a href="#æ•°æ®é›†ï¼ˆdata-setï¼‰" class="headerlink" title="æ•°æ®é›†ï¼ˆdata setï¼‰"></a>æ•°æ®é›†ï¼ˆdata setï¼‰</h2><table>
<thead>
<tr>
<th align="left">ç‰¹æ€§</th>
<th align="left">è®­ç»ƒé›†ï¼ˆTraining Setï¼‰</th>
<th align="left">éªŒè¯é›†ï¼ˆValidation Setï¼‰</th>
<th align="left">æµ‹è¯•é›†ï¼ˆTest Setï¼‰</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>ç”¨é€”</strong></td>
<td align="left">è®­ç»ƒæ¨¡å‹</td>
<td align="left">è°ƒä¼˜æ¨¡å‹å’Œè¶…å‚æ•°</td>
<td align="left">æœ€ç»ˆè¯„ä¼°æ¨¡å‹</td>
</tr>
<tr>
<td align="left"><strong>æ•°æ®ä½¿ç”¨</strong></td>
<td align="left">å¤šæ¬¡è¿­ä»£ä½¿ç”¨</td>
<td align="left">è°ƒä¼˜è¿‡ç¨‹ä¸­ä½¿ç”¨</td>
<td align="left">è®­ç»ƒå’Œè°ƒä¼˜å®Œæˆåä½¿ç”¨</td>
</tr>
<tr>
<td align="left"><strong>æ•°æ®ä¾èµ–</strong></td>
<td align="left">ç”¨äºè°ƒæ•´æ¨¡å‹å‚æ•°</td>
<td align="left">ç”¨äºè°ƒæ•´è¶…å‚æ•°ï¼Œä¸å‚ä¸è®­ç»ƒ</td>
<td align="left">ä¸å‚ä¸è®­ç»ƒå’Œè°ƒä¼˜</td>
</tr>
<tr>
<td align="left"><strong>æ•°æ®ç‹¬ç«‹æ€§</strong></td>
<td align="left">ä¸ç‹¬ç«‹</td>
<td align="left">ç‹¬ç«‹äºè®­ç»ƒé›†</td>
<td align="left">ç‹¬ç«‹äºè®­ç»ƒé›†å’ŒéªŒè¯é›†</td>
</tr>
</tbody></table>
<ul>
<li>é˜²æ­¢è¿‡æ‹Ÿåˆï¼šé€šè¿‡éªŒè¯é›†å¯ä»¥ç›‘æ§æ¨¡å‹æ˜¯å¦è¿‡æ‹Ÿåˆï¼Œå³åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°è‰¯å¥½ä½†åœ¨éªŒè¯é›†ä¸Šè¡¨ç°ä¸ä½³ã€‚</li>
<li>æ¨¡å‹é€‰æ‹©ï¼šä¸åŒçš„æ¨¡å‹å’Œè¶…å‚æ•°è®¾ç½®åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°å·®å¼‚ï¼Œå¯ä»¥å¸®åŠ©é€‰æ‹©æœ€ä½³æ¨¡å‹ã€‚</li>
<li>è¯„ä¼°æ³›åŒ–èƒ½åŠ›ï¼šæµ‹è¯•é›†çš„è¡¨ç°åæ˜ äº†æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„æ€§èƒ½ï¼Œæ˜¯è¡¡é‡æ¨¡å‹å®é™…åº”ç”¨æ•ˆæœçš„é‡è¦æŒ‡æ ‡ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ è½½Irisæ•°æ®é›†</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å°†ç›®æ ‡å˜é‡è¿›è¡ŒOne-hotç¼–ç </span></span><br><span class="line">encoder = OneHotEncoder(sparse_output=<span class="literal">False</span>)</span><br><span class="line">y = encoder.fit_transform(y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ’åˆ†è®­ç»ƒé›†ï¼ˆ60%ï¼‰ï¼Œä¸´æ—¶é›†ï¼ˆ40%ï¼‰</span></span><br><span class="line">X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=<span class="number">0.4</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ’åˆ†éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼ˆå„å ä¸´æ—¶é›†çš„ä¸€åŠï¼Œå³20%ï¼‰</span></span><br><span class="line">X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=<span class="number">0.5</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºTensorFlowæ•°æ®é›†</span></span><br><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(<span class="number">32</span>)</span><br><span class="line">val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(<span class="number">32</span>)</span><br><span class="line">test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œæ¨¡å‹</span></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(X.shape[<span class="number">1</span>],)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¼–è¯‘æ¨¡å‹</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒæ¨¡å‹</span></span><br><span class="line">history = model.fit(train_dataset, epochs=<span class="number">10</span>, validation_data=val_dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¯„ä¼°æ¨¡å‹</span></span><br><span class="line">test_loss, test_acc = model.evaluate(test_dataset)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Test accuracy: <span class="subst">&#123;test_acc&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># Epoch 1/10</span></span><br><span class="line"><span class="comment"># 3/3 â”â”â” 1s 53ms/step - accuracy: 0.2373 - loss: 1.5473 - val_accuracy: 0.0000e+00 - val_loss: 1.# 4492</span></span><br><span class="line"><span class="comment"># Epoch 2/10</span></span><br><span class="line"><span class="comment"># 3/3 â”â”â” 0s 5ms/step - accuracy: 0.0389 - loss: 1.3015 - val_accuracy: 0.2000 - val_loss: 1.2407</span></span><br><span class="line"><span class="comment"># Epoch 3/10</span></span><br><span class="line"><span class="comment"># 3/3 â”â”â” 0s 4ms/step - accuracy: 0.2879 - loss: 1.1624 - val_accuracy: 0.4000 - val_loss: 1.1172</span></span><br><span class="line"><span class="comment"># Epoch 4/10</span></span><br><span class="line"><span class="comment"># 3/3 â”â”â” 0s 4ms/step - accuracy: 0.3089 - loss: 1.0956 - val_accuracy: 0.4000 - val_loss: 1.0437</span></span><br><span class="line"><span class="comment"># Epoch 5/10</span></span><br><span class="line"><span class="comment"># 3/3 â”â”â” 0s 4ms/step - accuracy: 0.3262 - loss: 1.0574 - val_accuracy: 0.4000 - val_loss: 0.9875</span></span><br><span class="line"><span class="comment"># Epoch 6/10</span></span><br><span class="line"><span class="comment"># 3/3 â”â”â” 0s 4ms/step - accuracy: 0.3262 - loss: 1.0167 - val_accuracy: 0.4000 - val_loss: 0.9420</span></span><br><span class="line"><span class="comment"># Epoch 7/10</span></span><br><span class="line"><span class="comment"># 3/3 â”â”â” 0s 4ms/step - accuracy: 0.3373 - loss: 0.9718 - val_accuracy: 0.7333 - val_loss: 0.9028</span></span><br><span class="line"><span class="comment"># Epoch 8/10</span></span><br><span class="line"><span class="comment"># 3/3 â”â”â” 0s 4ms/step - accuracy: 0.5963 - loss: 0.9303 - val_accuracy: 0.8333 - val_loss: 0.8623</span></span><br><span class="line"><span class="comment"># Epoch 9/10</span></span><br><span class="line"><span class="comment"># 3/3 â”â”â” 0s 4ms/step - accuracy: 0.7127 - loss: 0.8940 - val_accuracy: 0.8333 - val_loss: 0.8183</span></span><br><span class="line"><span class="comment"># Epoch 10/10</span></span><br><span class="line"><span class="comment"># 3/3 â”â”â”â” 0s 4ms/step - accuracy: 0.7016 - loss: 0.8614 - val_accuracy: 0.8333 - val_loss: 0.7730</span></span><br><span class="line"><span class="comment"># 1/1 â”â”â”â” 0s 6ms/step - accuracy: 0.5667 - loss: 0.8338</span></span><br><span class="line"><span class="comment"># Test accuracy: 0.5666666626930237</span></span><br></pre></td></tr></table></figure>

<h3 id="åå·®ï¼ˆBiasï¼‰å’Œæ–¹å·®ï¼ˆVarianceï¼‰"><a href="#åå·®ï¼ˆBiasï¼‰å’Œæ–¹å·®ï¼ˆVarianceï¼‰" class="headerlink" title="åå·®ï¼ˆBiasï¼‰å’Œæ–¹å·®ï¼ˆVarianceï¼‰"></a>åå·®ï¼ˆBiasï¼‰å’Œæ–¹å·®ï¼ˆVarianceï¼‰</h3><ul>
<li>åå·®ï¼ˆBiasï¼‰è¡¨ç¤ºæ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„åç¦»ç¨‹åº¦ï¼Œå®ƒåæ˜ äº†æ¨¡å‹å¯¹çœŸå®æ•°æ®çš„æ‹Ÿåˆèƒ½åŠ›ã€‚<ul>
<li>é«˜åå·®é€šå¸¸æ„å‘³ç€æ¨¡å‹è¿‡äºç®€å•ï¼Œä¸èƒ½å¾ˆå¥½åœ°æ•æ‰æ•°æ®ä¸­çš„æ¨¡å¼ï¼Œå¯¼è‡´æ¬ æ‹Ÿåˆã€‚</li>
</ul>
</li>
<li>æ–¹å·®ï¼ˆVarianceï¼‰è¡¨ç¤ºæ¨¡å‹é¢„æµ‹ç»“æœçš„å˜åŒ–ç¨‹åº¦ï¼Œå®ƒåæ˜ äº†æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„æ•æ„Ÿåº¦ã€‚<ul>
<li>é«˜æ–¹å·®é€šå¸¸æ„å‘³ç€æ¨¡å‹è¿‡äºå¤æ‚ï¼Œè¿‡äºä¾èµ–è®­ç»ƒæ•°æ®ä¸­çš„å™ªå£°ï¼Œå¯¼è‡´è¿‡æ‹Ÿåˆã€‚</li>
</ul>
</li>
</ul>
<p>å‡è®¾å­˜åœ¨ä¸€ä¸ªåªæœ‰ $ğ‘¥_1$ å’Œ $ğ‘¥_2$ ä¸¤ä¸ªç‰¹å¾çš„äºŒç»´æ•°æ®é›†æ•°æ®é›†:</p>
<p><img data-src="/images/DeepLearning/dataset_fitting.png"></p>
<ul>
<li>å¦‚æœç»™è¿™ä¸ªæ•°æ®é›†æ‹Ÿåˆä¸€æ¡ç›´çº¿ï¼Œå¯èƒ½å¾—åˆ°ä¸€ä¸ªé€»è¾‘å›å½’æ‹Ÿåˆï¼Œä½†å®ƒå¹¶ä¸èƒ½å¾ˆå¥½åœ°æ‹Ÿåˆè¯¥æ•°æ®ï¼Œè¿™æ˜¯é«˜åå·®ï¼ˆhigh biasï¼‰ã€‚<ul>
<li>æ¬ æ‹Ÿåˆï¼ˆUnderfittingï¼‰ï¼šé«˜åå·®ã€ä½æ–¹å·®ã€‚æ¨¡å‹è¿‡äºç®€å•ï¼Œæ— æ³•æ•æ‰æ•°æ®ä¸­çš„æ¨¡å¼ã€‚</li>
</ul>
</li>
<li>å¦‚æœæ‹Ÿåˆä¸€ä¸ªéå¸¸å¤æ‚çš„åˆ†ç±»å™¨ï¼Œæ¯”å¦‚æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå¯èƒ½å°±éå¸¸é€‚ç”¨äºè¿™ä¸ªæ•°æ®é›†ï¼Œä½†ä¹Ÿä¸æ˜¯ä¸€ç§å¾ˆå¥½çš„æ‹Ÿåˆæ–¹å¼åˆ†ç±»å™¨ï¼Œæ–¹å·®è¾ƒé«˜ï¼ˆ high varianceï¼‰ã€‚<ul>
<li>è¿‡æ‹Ÿåˆï¼ˆOverfittingï¼‰ï¼šä½åå·®ã€é«˜æ–¹å·®ã€‚æ¨¡å‹è¿‡äºå¤æ‚ï¼Œæ•æ‰åˆ°äº†è®­ç»ƒæ•°æ®ä¸­çš„å™ªå£°ã€‚</li>
</ul>
</li>
<li>åœ¨ä¸Šè¿°ä¸¤è€…ä¹‹é—´ï¼Œå¯èƒ½è¿˜æœ‰ä¸€äº›å¤æ‚ç¨‹åº¦é€‚ä¸­çš„åˆ†ç±»å™¨ï¼Œè¿™ä¸ªæ•°æ®æ‹Ÿåˆçœ‹èµ·æ¥æ›´åŠ åˆç†ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œé€‚åº¦æ‹Ÿåˆâ€ï¼ˆjust rightï¼‰ã€‚<ul>
<li>æœ€ä½³æ¨¡å‹ï¼ˆOptimal Modelï¼‰ï¼šé€‚ä¸­çš„åå·®å’Œæ–¹å·®ï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒæ•°æ®å’Œæ–°æ•°æ®ä¸Šè¡¨ç°è‰¯å¥½ã€‚</li>
</ul>
</li>
</ul>
<h2 id="æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰"><a href="#æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰" class="headerlink" title="æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰"></a>æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰</h2><p>æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰æ˜¯æŒ‡ä¸€ç»„æŠ€æœ¯å’Œç­–ç•¥ï¼Œé€šè¿‡é™åˆ¶æ¨¡å‹çš„å¤æ‚åº¦ï¼Œé˜²æ­¢å…¶è¿‡äºä¾èµ–è®­ç»ƒæ•°æ®ä¸­çš„å™ªå£°å’Œç»†èŠ‚ï¼Œä¸»è¦ç›®çš„æ˜¯å‡å°‘æ¨¡å‹çš„è¿‡æ‹Ÿåˆï¼ˆoverfittingï¼‰ï¼Œä»è€Œæé«˜æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p>æ­£åˆ™åŒ–æ–¹æ³•ï¼š</p>
<ul>
<li>L1æ­£åˆ™åŒ–ï¼ˆLassoï¼‰ï¼šåœ¨æŸå¤±å‡½æ•°ä¸­åŠ å…¥æƒé‡ç»å¯¹å€¼çš„å’Œã€‚<br>$$ \text{Loss} &#x3D; \text{Original Loss} + \lambda \sum_{i} |w_i| $$<br>$$ å…¶ä¸­ï¼Œğœ† æ˜¯æ­£åˆ™åŒ–å‚æ•°ï¼Œæ§åˆ¶æ­£åˆ™åŒ–é¡¹çš„å¼ºåº¦ï¼› ğ‘¤_ğ‘– æ˜¯æ¨¡å‹çš„æƒé‡ã€‚ $$<ul>
<li>L1æ­£åˆ™åŒ–å€¾å‘äºä½¿ä¸€äº›æƒé‡å˜ä¸ºé›¶ï¼Œä»è€Œäº§ç”Ÿç¨€ç–æ¨¡å‹ï¼Œé€‚ç”¨äºç‰¹å¾é€‰æ‹©ã€‚</li>
</ul>
</li>
<li>L2æ­£åˆ™åŒ–ï¼ˆRidgeï¼‰ï¼šåœ¨æŸå¤±å‡½æ•°ä¸­åŠ å…¥æƒé‡å¹³æ–¹å’Œã€‚<br>$$ L(\mathbf{w}) &#x3D; L_0(\mathbf{w}) + \lambda \sum_{i} w_i^2 $$<br>$$ å…¶ä¸­ï¼ŒL(\mathbf{w}) æ˜¯æ­£åˆ™åŒ–åçš„æ€»æŸå¤±å‡½æ•°ï¼›L_0(\mathbf{w}) æ˜¯åŸå§‹æŸå¤±å‡½æ•°ï¼ˆå¦‚å‡æ–¹è¯¯å·®æˆ–äº¤å‰ç†µï¼‰ï¼›$$<br>$$ ğœ† æ˜¯æ­£åˆ™åŒ–å‚æ•°ï¼Œæ§åˆ¶æ­£åˆ™åŒ–é¡¹çš„å¼ºåº¦ï¼›ğ‘¤_ğ‘– æ˜¯æ¨¡å‹çš„æƒé‡ã€‚ $$<br>å‡è®¾ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥æ›´æ–°æ¨¡å‹æƒé‡ã€‚åœ¨æ²¡æœ‰æ­£åˆ™åŒ–çš„æƒ…å†µä¸‹ï¼Œæƒé‡æ›´æ–°çš„å…¬å¼æ˜¯ï¼š<br>$$ w_i \leftarrow w_i - \eta \frac{\partial L_0(\mathbf{w})}{\partial w_i} $$<br>$$ å…¶ä¸­ï¼ŒÎ· æ˜¯å­¦ä¹ ç‡ï¼›\frac{\partial L_0(\mathbf{w})}{\partial w_i} æ˜¯åŸå§‹æŸå¤±å‡½æ•°å…³äºæƒé‡ ğ‘¤_ğ‘– çš„æ¢¯åº¦ã€‚ $$<br>åŠ å…¥L2æ­£åˆ™åŒ–åï¼ŒæŸå¤±å‡½æ•°å˜ä¸º $ğ¿(ğ‘¤)$ï¼Œè®¡ç®—æ­£åˆ™åŒ–åæŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼š<br>$$ \frac{\partial L(\mathbf{w})}{\partial w_i} &#x3D; \frac{\partial L_0(\mathbf{w})}{\partial w_i} + \frac{\partial}{\partial w_i} \left( \lambda \sum w_i^2 \right) &#x3D; \frac{\partial L_0(\mathbf{w})}{\partial w_i} + 2\lambda w_i $$<br>äºæ˜¯ï¼Œæƒé‡æ›´æ–°å…¬å¼å˜ä¸ºï¼š<br>$$ w_i \leftarrow w_i - \eta \left( \frac{\partial L_0(\mathbf{w})}{\partial w_i} + 2\lambda w_i \right) &#x3D; \begin{cases}<br>w_i - \eta \frac{\partial L_0(\mathbf{w})}{\partial w_i} &amp; \text{åŸå§‹æ¢¯åº¦ä¸‹é™é¡¹} \\<br>w_i - 2\eta\lambda w_i &amp; \text{æƒé‡è¡°å‡é¡¹}<br>\end{cases} $$<ul>
<li>è¿™è¡¨æ˜åœ¨æ¯ä¸€æ­¥æ›´æ–°ä¸­ï¼Œæƒé‡ä¸ä»…æ ¹æ®åŸå§‹æŸå¤±å‡½æ•°çš„æ¢¯åº¦è¿›è¡Œæ›´æ–°ï¼Œè¿˜ä¼šä¹˜ä¸Šä¸€ä¸ªå› å­ $(1 - 2\eta\lambda)$ ä½¿å¾—æƒé‡é€æ¸å‡å°ï¼ˆæƒé‡è¡°å‡ï¼‰ã€‚</li>
<li>è¾ƒå°çš„æƒé‡å€¼æ„å‘³ç€æ¨¡å‹æ›´ç®€å•ï¼Œæ›´ä¸å®¹æ˜“è¿‡æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>L2æ­£åˆ™åŒ–é€šè¿‡åœ¨æŸå¤±å‡½æ•°ä¸­åŠ å…¥æƒé‡å¹³æ–¹å’Œçš„æƒ©ç½šé¡¹ï¼Œå¯¼è‡´æƒé‡æ›´æ–°æ—¶æœ‰ä¸€ä¸ªé¢å¤–çš„è¡°å‡é¡¹ï¼Œä»è€Œé€æ¸å‡å°æƒé‡å€¼ã€‚</li>
</ul>
</li>
<li>Dropoutï¼šä¸€ç§åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºå¿½ç•¥ä¸€éƒ¨åˆ†ç¥ç»å…ƒçš„æŠ€æœ¯ã€‚åœ¨æ¯æ¬¡è®­ç»ƒè¿­ä»£æ—¶ï¼Œéšæœºé€‰æ‹©ä¸€å®šæ¯”ä¾‹çš„ç¥ç»å…ƒï¼Œå¹¶å°†å®ƒä»¬æš‚æ—¶ä»ç½‘ç»œä¸­ç§»é™¤ã€‚<ul>
<li>ç›¸å½“äºåœ¨è®­ç»ƒå¤šä¸ªä¸åŒçš„å­ç½‘ç»œï¼Œå¹¶å°†å®ƒä»¬çš„é¢„æµ‹ç»“æœè¿›è¡Œå¹³å‡ï¼Œä»è€Œå‡å°‘è¿‡æ‹Ÿåˆã€‚</li>
</ul>
</li>
<li>æ—©åœï¼ˆEarly Stoppingï¼‰ï¼šç›‘æ§éªŒè¯é›†çš„æ€§èƒ½ï¼Œå¦‚æœåœ¨è‹¥å¹²ä¸ªè®­ç»ƒè¿­ä»£åéªŒè¯è¯¯å·®ä¸å†é™ä½ï¼Œåˆ™æå‰åœæ­¢è®­ç»ƒã€‚<ul>
<li>æ—©åœå¯ä»¥é˜²æ­¢æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿‡æ‹Ÿåˆã€‚</li>
</ul>
</li>
<li>æ•°æ®å¢å¼ºï¼ˆData Augmentationï¼‰ï¼šé€šè¿‡å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œéšæœºå˜æ¢ï¼ˆå¦‚æ—‹è½¬ã€ç¼©æ”¾ã€å¹³ç§»ã€ç¿»è½¬ç­‰ï¼‰ï¼Œç”Ÿæˆæ›´å¤šçš„è®­ç»ƒæ•°æ®ï¼Œå¢åŠ æ•°æ®å¤šæ ·æ€§ã€‚<ul>
<li>æ•°æ®å¢å¼ºåœ¨å›¾åƒåˆ†ç±»å’Œç›®æ ‡æ£€æµ‹ä¸­å°¤å…¶æœ‰æ•ˆï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ul>
</li>
<li>æ‰¹å½’ä¸€åŒ–ï¼ˆBatch Normalizationï¼‰ï¼šé€šè¿‡æ ‡å‡†åŒ–æ¯ä¸€æ‰¹æ¬¡çš„æ•°æ®ï¼Œä½¿å…¶å…·æœ‰å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„ç‰¹æ€§ï¼Œè¿›è€Œç¨³å®šæ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹ã€‚<br>1.è®¡ç®—æ‰¹æ¬¡å‡å€¼å’Œæ–¹å·®ï¼šå¯¹äºç»™å®šçš„æ‰¹æ¬¡è¾“å…¥ $x &#x3D; \lbrace x_1, x_2, â€¦, x_ğ‘š \rbrace$ï¼Œè®¡ç®—å‡å€¼ $\mu_B$ å’Œæ–¹å·® $\sigma_B^2$<br>  $$ \mu_B &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^m x_i $$<br>  $$ \sigma_B^2 &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^m (x_i - \mu_B)^2 $$<br>2.æ ‡å‡†åŒ–ï¼šå°†æ¯ä¸ªè¾“å…¥æ ‡å‡†åŒ–ä¸ºå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„å½¢å¼<br>  $$ \hat{x}_i &#x3D; \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}} $$<br>  $$ å…¶ä¸­ï¼Œ\epsilon æ˜¯ä¸€ä¸ªå°çš„å¸¸æ•°ï¼Œç”¨äºé˜²æ­¢é™¤ä»¥é›¶çš„æƒ…å†µã€‚ $$<br>3.ç¼©æ”¾å’Œå¹³ç§»ï¼šå¼•å…¥å¯å­¦ä¹ çš„å‚æ•° $\gamma$ å’Œ $\beta$ï¼Œå¯¹æ ‡å‡†åŒ–åçš„æ•°æ®è¿›è¡Œç¼©æ”¾å’Œå¹³ç§»ï¼Œä»¥æ¢å¤æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›<br>  $$ y_i &#x3D; \gamma \hat{x}_i + \beta $$<br>  $$ å…¶ä¸­ï¼Œ\gamma å’Œ \beta æ˜¯ä¸è¾“å…¥çš„æ¯ä¸ªç»´åº¦ç›¸å¯¹åº”çš„å¯è®­ç»ƒå‚æ•°ã€‚ $$<ul>
<li>ç¨³å®šè®­ç»ƒè¿‡ç¨‹ï¼šæ‰¹å½’ä¸€åŒ–é€šè¿‡å‡å°‘è¾“å…¥æ•°æ®çš„å˜åŒ–èŒƒå›´ï¼Œç¨³å®šäº†æ¢¯åº¦çš„æ›´æ–°è¿‡ç¨‹ï¼Œä½¿å¾—æ¨¡å‹è®­ç»ƒæ›´åŠ ç¨³å®šï¼Œå¹¶ä¸”å…è®¸ä½¿ç”¨æ›´é«˜çš„å­¦ä¹ ç‡ã€‚</li>
<li>åŠ é€Ÿæ”¶æ•›ï¼šé€šè¿‡æ ‡å‡†åŒ–è¾“å…¥æ•°æ®ï¼Œæ‰¹å½’ä¸€åŒ–å¯ä»¥ä½¿å¾—æŸå¤±å‡½æ•°çš„ä¼˜åŒ–è·¯å¾„æ›´åŠ å¹³æ»‘ï¼Œä»è€ŒåŠ é€Ÿæ¨¡å‹çš„æ”¶æ•›ã€‚</li>
<li>å‡å°‘å¯¹åˆå§‹åŒ–çš„ä¾èµ–ï¼šæ‰¹å½’ä¸€åŒ–é™ä½äº†æƒé‡åˆå§‹åŒ–å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œä½¿å¾—æ¨¡å‹å¯¹æƒé‡åˆå§‹åŒ–çš„é€‰æ‹©æ›´åŠ é²æ£’ã€‚</li>
<li>æ­£åˆ™åŒ–æ•ˆæœï¼šæ‰¹å½’ä¸€åŒ–åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹æ¯ä¸ªæ‰¹æ¬¡çš„æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ï¼Œè¿™å¼•å…¥äº†ä¸€å®šçš„å™ªå£°ï¼Œç›¸å½“äºä¸€ç§æ­£åˆ™åŒ–æ‰‹æ®µï¼Œæœ‰åŠ©äºå‡å°‘æ¨¡å‹çš„è¿‡æ‹Ÿåˆã€‚</li>
</ul>
</li>
</ul>
<p>ä»¥ä¸‹æ˜¯ä¸€ä¸ªåŸºäºTensorFlowå’ŒKerasï¼Œåœ¨MNISTæ•°æ®é›†ä¸Šä½¿ç”¨L2æ­£åˆ™åŒ–å’ŒDropoutçš„ç®€å•ç¤ºä¾‹ä»£ç ï¼š</p>
<div class="tabs" id="deeplearning-regularization"><ul class="nav-tabs"><li class="tab active"><a href="#deeplearning-regularization-1">L2æ­£åˆ™åŒ–&Dropout</a></li><li class="tab"><a href="#deeplearning-regularization-2">BatchNormalization</a></li></ul><div class="tab-content"><div class="tab-pane active" id="deeplearning-regularization-1"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ è½½MNISTæ•°æ®é›†</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å°†æ ‡ç­¾è¿›è¡Œone-hotç¼–ç </span></span><br><span class="line">y_train = to_categorical(y_train, <span class="number">10</span>)</span><br><span class="line">y_test = to_categorical(y_test, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ„å»ºæ¨¡å‹</span></span><br><span class="line">model = Sequential([</span><br><span class="line">    Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)), <span class="comment"># å°†28x28çš„è¾“å…¥å›¾åƒå±•å¹³æˆä¸€ç»´å‘é‡</span></span><br><span class="line">    Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>, kernel_regularizer=l2(<span class="number">0.01</span>)),  <span class="comment"># åŒ…å«128ä¸ªç¥ç»å…ƒï¼Œå¹¶åº”ç”¨L2æ­£åˆ™åŒ–</span></span><br><span class="line">    Dropout(<span class="number">0.5</span>),  <span class="comment"># Dropout, éšæœºä¸¢å¼ƒ50%çš„ç¥ç»å…ƒ</span></span><br><span class="line">    Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, kernel_regularizer=l2(<span class="number">0.01</span>)),  <span class="comment"># åŒ…å«64ä¸ªç¥ç»å…ƒï¼Œå¹¶åº”ç”¨L2æ­£åˆ™åŒ–</span></span><br><span class="line">    Dropout(<span class="number">0.5</span>),  <span class="comment"># Dropout, éšæœºä¸¢å¼ƒ50%çš„ç¥ç»å…ƒ</span></span><br><span class="line">    Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)  <span class="comment"># åŒ…å«10ä¸ªç¥ç»å…ƒï¼Œä½¿ç”¨softmaxæ¿€æ´»å‡½æ•°ï¼Œç”¨äºå¤šåˆ†ç±»è¾“å‡º</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¼–è¯‘æ¨¡å‹</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨20%çš„æ•°æ®ä½œä¸ºéªŒè¯é›†ï¼‰</span></span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">10</span>, validation_split=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¯„ä¼°æ¨¡å‹</span></span><br><span class="line">test_loss, test_acc = model.evaluate(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Test accuracy: <span class="subst">&#123;test_acc&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># Epoch 1/10</span></span><br><span class="line"><span class="comment"># 1500/1500 â”â”â” 5s 3ms/step - accuracy: 0.6644 - loss: 1.9379 - val_accuracy: 0.9147 - val_loss: 0.6313</span></span><br><span class="line"><span class="comment"># Epoch 2/10</span></span><br><span class="line"><span class="comment"># 1500/1500 â”â”â” 4s 3ms/step - accuracy: 0.8497 - loss: 0.8360 - val_accuracy: 0.9255 - val_loss: 0.5732</span></span><br><span class="line"><span class="comment"># Epoch 3/10</span></span><br><span class="line"><span class="comment"># 1500/1500 â”â”â” 4s 3ms/step - accuracy: 0.8622 - loss: 0.7762 - val_accuracy: 0.9300 - val_loss: 0.5373</span></span><br><span class="line"><span class="comment"># Epoch 4/10</span></span><br><span class="line"><span class="comment"># 1500/1500 â”â”â” 4s 3ms/step - accuracy: 0.8674 - loss: 0.7401 - val_accuracy: 0.9354 - val_loss: 0.5171</span></span><br><span class="line"><span class="comment"># Epoch 5/10</span></span><br><span class="line"><span class="comment"># 1500/1500 â”â”â” 4s 3ms/step - accuracy: 0.8719 - loss: 0.7179 - val_accuracy: 0.9341 - val_loss: 0.5050</span></span><br><span class="line"><span class="comment"># Epoch 6/10</span></span><br><span class="line"><span class="comment"># 1500/1500 â”â”â” 4s 3ms/step - accuracy: 0.8753 - loss: 0.7080 - val_accuracy: 0.9252 - val_loss: 0.5304</span></span><br><span class="line"><span class="comment"># Epoch 7/10</span></span><br><span class="line"><span class="comment"># 1500/1500 â”â”â” 4s 3ms/step - accuracy: 0.8816 - loss: 0.6894 - val_accuracy: 0.9362 - val_loss: 0.4996</span></span><br><span class="line"><span class="comment"># Epoch 8/10</span></span><br><span class="line"><span class="comment"># 1500/1500 â”â”â” 4s 3ms/step - accuracy: 0.8813 - loss: 0.6833 - val_accuracy: 0.9327 - val_loss: 0.4979</span></span><br><span class="line"><span class="comment"># Epoch 9/10</span></span><br><span class="line"><span class="comment"># 1500/1500 â”â”â” 4s 3ms/step - accuracy: 0.8792 - loss: 0.6844 - val_accuracy: 0.9377 - val_loss: 0.4793</span></span><br><span class="line"><span class="comment"># Epoch 10/10</span></span><br><span class="line"><span class="comment"># 1500/1500 â”â”â” 4s 3ms/step - accuracy: 0.8827 - loss: 0.6772 - val_accuracy: 0.9364 - val_loss: 0.4848</span></span><br><span class="line"><span class="comment"># 313/313 â”â”â” 0s 1ms/step - accuracy: 0.9260 - loss: 0.5191</span></span><br></pre></td></tr></table></figure></div><div class="tab-pane" id="deeplearning-regularization-2"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, Flatten, BatchNormalization</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŠ è½½MNISTæ•°æ®é›†</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å°†æ ‡ç­¾è¿›è¡Œone-hotç¼–ç </span></span><br><span class="line">y_train = to_categorical(y_train, <span class="number">10</span>)</span><br><span class="line">y_test = to_categorical(y_test, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ„å»ºæ¨¡å‹</span></span><br><span class="line">model = Sequential([</span><br><span class="line">    Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">    Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    BatchNormalization(), <span class="comment"># åé¢è·Ÿç€ä¸€ä¸ª BatchNormalization å±‚è¿›è¡Œæ‰¹å½’ä¸€åŒ–</span></span><br><span class="line">    Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    BatchNormalization(), <span class="comment"># åé¢è·Ÿç€ä¸€ä¸ª BatchNormalization å±‚è¿›è¡Œæ‰¹å½’ä¸€åŒ–</span></span><br><span class="line">    Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¼–è¯‘æ¨¡å‹</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒæ¨¡å‹</span></span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">10</span>, validation_split=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¯„ä¼°æ¨¡å‹</span></span><br><span class="line">test_loss, test_acc = model.evaluate(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Test accuracy: <span class="subst">&#123;test_acc&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure></div></div></div>

<h2 id="æ¢¯åº¦æ¶ˆå¤±ï¼ˆvanishing-gradientï¼‰"><a href="#æ¢¯åº¦æ¶ˆå¤±ï¼ˆvanishing-gradientï¼‰" class="headerlink" title="æ¢¯åº¦æ¶ˆå¤±ï¼ˆvanishing gradientï¼‰"></a>æ¢¯åº¦æ¶ˆå¤±ï¼ˆvanishing gradientï¼‰</h2><p>æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼ˆVanishing Gradient Problemï¼‰åœ¨æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰è®­ç»ƒä¸­çš„ä¸€ä¸ªä¸»è¦éšœç¢ã€‚åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œç¥ç»ç½‘ç»œçš„æ¯ä¸€å±‚ä¼šæ ¹æ®å…¶æƒé‡å’Œå‰ä¸€å±‚çš„è¾“å‡ºè®¡ç®—æ¢¯åº¦ã€‚è¿™äº›æ¢¯åº¦è¢«ç”¨äºæ›´æ–°ç½‘ç»œçš„æƒé‡ï¼Œä»è€Œæœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚ç„¶è€Œï¼Œå½“ç½‘ç»œå±‚æ•°è¾ƒå¤šæ—¶ï¼Œä»è¾“å‡ºå±‚åå‘ä¼ æ’­åˆ°è¾“å…¥å±‚çš„æ¢¯åº¦ä¼šé€å±‚ç›¸ä¹˜ï¼Œå¦‚æœæŸäº›æ¡ä»¶ï¼ˆå¦‚æ¿€æ´»å‡½æ•°å’Œæƒé‡åˆå§‹åŒ–ï¼‰ä¸å½“ï¼Œè¿™äº›æ¢¯åº¦å¯èƒ½ä¼šé€æ¸å˜å¾—éå¸¸å°ï¼Œç”šè‡³æ¥è¿‘äºé›¶ï¼Œå¯¼è‡´å‰å±‚çš„æƒé‡å‡ ä¹ä¸æ›´æ–°ã€‚</p>
<p>æ¿€æ´»å‡½æ•°çš„å½±å“ï¼šSigmoidå’ŒTanhæ¿€æ´»å‡½æ•°çš„è¾“å‡ºèŒƒå›´æ˜¯æœ‰é™çš„ï¼ˆSigmoidåœ¨(0, 1)ï¼ŒTanhåœ¨(-1, 1)ï¼‰ï¼Œå®ƒä»¬çš„å¯¼æ•°æœ€å¤§å€¼éƒ½å°äº1ã€‚å½“è¾“å…¥è¾ƒå¤§æ—¶ï¼Œå¯¼æ•°ä¼šè¶‹è¿‘äº0ã€‚</p>
<ul>
<li>è¿™ç§ç‰¹æ€§åœ¨å¤šå±‚ç½‘ç»œä¸­ä¼šå¯¼è‡´æ¢¯åº¦è¿…é€Ÿå˜å°ï¼Œä»è€Œå¯¼è‡´å‰å‡ å±‚çš„æ¢¯åº¦æ¶ˆå¤±ã€‚</li>
</ul>
<p>æƒé‡åˆå§‹åŒ–çš„å½±å“ï¼šä¸åˆé€‚çš„æƒé‡åˆå§‹åŒ–ä¹Ÿä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ã€‚è‹¥æƒé‡åˆå§‹åŒ–è¿‡å°ï¼Œæ¿€æ´»å€¼ä¼šè¶‹è¿‘äºæ¿€æ´»å‡½æ•°çš„é¥±å’ŒåŒºé—´ï¼ˆå¦‚sigmoidçš„0æˆ–1ï¼‰ï¼Œè¿™ä¼šä½¿å¾—åå‘ä¼ æ’­ä¸­çš„æ¢¯åº¦å˜å¾—éå¸¸å°ã€‚</p>
<h2 id="æ¢¯åº¦çˆ†ç‚¸ï¼ˆexploding-gradientï¼‰"><a href="#æ¢¯åº¦çˆ†ç‚¸ï¼ˆexploding-gradientï¼‰" class="headerlink" title="æ¢¯åº¦çˆ†ç‚¸ï¼ˆexploding gradientï¼‰"></a>æ¢¯åº¦çˆ†ç‚¸ï¼ˆexploding gradientï¼‰</h2><p>æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼ˆExploding Gradient Problemï¼‰åœ¨æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰è®­ç»ƒä¸­æ˜¯å¦ä¸€ä¸ªå¸¸è§çš„é—®é¢˜ï¼Œä¸æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ç›¸å¯¹ç«‹ã€‚æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ä¼šå¯¼è‡´æ¨¡å‹å‚æ•°æ›´æ–°è¿‡å¿«ï¼Œä»è€Œä½¿æ¨¡å‹ä¸ç¨³å®šï¼Œç”šè‡³ä½¿æŸå¤±å‡½æ•°å‘æ•£ï¼ˆå³å˜å¾—éå¸¸å¤§ï¼‰ã€‚</p>
<p>è§£å†³æ–¹æ³•ï¼š</p>
<ul>
<li>æ¢¯åº¦è£å‰ªï¼ˆGradient Clippingï¼‰ï¼šåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œè‹¥æ¢¯åº¦è¶…è¿‡æŸä¸ªé˜ˆå€¼ï¼Œåˆ™å¯¹å…¶è¿›è¡Œè£å‰ªã€‚ä¾‹å¦‚ï¼Œå°†æ¢¯åº¦å€¼é™åˆ¶åœ¨æŸä¸ªèŒƒå›´å†…ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç®€å•çš„çº¿æ€§æ¨¡å‹</span></span><br><span class="line">model = nn.Linear(<span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç”Ÿæˆä¸€äº›éšæœºæ•°æ®</span></span><br><span class="line">inputs = torch.randn(<span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line">targets = torch.randn(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒæ­¥éª¤</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    loss = criterion(outputs, targets)</span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ¢¯åº¦è£å‰ª</span></span><br><span class="line">    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>, Loss: <span class="subst">&#123;loss.item()&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="æ¢¯åº¦æ£€éªŒï¼ˆGradient-Checkingï¼‰"><a href="#æ¢¯åº¦æ£€éªŒï¼ˆGradient-Checkingï¼‰" class="headerlink" title="æ¢¯åº¦æ£€éªŒï¼ˆGradient Checkingï¼‰"></a>æ¢¯åº¦æ£€éªŒï¼ˆGradient Checkingï¼‰</h2><p>æ¢¯åº¦æ£€éªŒï¼ˆGradient Checkingï¼‰æ˜¯ä¸€ç§ç”¨äºéªŒè¯åå‘ä¼ æ’­å®ç°æ­£ç¡®æ€§çš„æ–¹æ³•ã€‚<br>1.å®šä¹‰æŸå¤±å‡½æ•°ï¼šå‡è®¾æŸå¤±å‡½æ•°ä¸º $ğ½(ğœƒ)$ï¼Œå…¶ä¸­ $ğœƒ$ è¡¨ç¤ºæ¨¡å‹çš„å‚æ•°ã€‚<br>2.è®¡ç®—æ•°å€¼æ¢¯åº¦ï¼šä½¿ç”¨ä»¥ä¸‹å…¬å¼è®¡ç®—æ•°å€¼æ¢¯åº¦<br>  $$ \frac{\partial J(\theta)}{\partial \theta_i} \approx \frac{J(\theta_i + \epsilon) - J(\theta_i - \epsilon)}{2\epsilon} $$<br>  $$ å…¶ä¸­ï¼Œğœ– æ˜¯ä¸€ä¸ªéå¸¸å°çš„å€¼ï¼Œä¸€èˆ¬å– ğœ– &#x3D; 10^{-7}ã€‚ $$<br>3.è®¡ç®—åå‘ä¼ æ’­æ¢¯åº¦ï¼šä½¿ç”¨åå‘ä¼ æ’­ç®—æ³•è®¡ç®—æŸå¤±å‡½æ•°ç›¸å¯¹äºæƒé‡çš„æ¢¯åº¦ã€‚<br>4.æ¯”è¾ƒæ¢¯åº¦ï¼šå°†æ•°å€¼æ¢¯åº¦ä¸åå‘ä¼ æ’­è®¡ç®—çš„æ¢¯åº¦è¿›è¡Œæ¯”è¾ƒã€‚</p>
<ul>
<li>å¦‚æœä¸¤è€…éå¸¸æ¥è¿‘ï¼Œåˆ™è¯´æ˜åå‘ä¼ æ’­å®ç°æ˜¯æ­£ç¡®çš„ï¼›</li>
<li>å¦‚æœå·®å¼‚è¾ƒå¤§ï¼Œåˆ™å¯èƒ½å­˜åœ¨é”™è¯¯ã€‚</li>
</ul>
<p>æ³¨æ„äº‹é¡¹ï¼š</p>
<ul>
<li>æ¢¯åº¦æ£€éªŒåªéªŒè¯å•ä¸ªå‚æ•°çš„æ¢¯åº¦æ˜¯å¦æ­£ç¡®ï¼Œæ— æ³•éªŒè¯æ•´ä¸ªåå‘ä¼ æ’­è¿‡ç¨‹çš„æ‰€æœ‰ç»†èŠ‚ã€‚å› æ­¤ï¼Œæ¢¯åº¦æ£€éªŒé€šè¿‡å¹¶ä¸æ„å‘³ç€åå‘ä¼ æ’­å®ç°å®Œå…¨æ²¡æœ‰é”™è¯¯ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">numerical_gradient</span>(<span class="params">f, x</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;è®¡ç®—å‡½æ•°fåœ¨xç‚¹çš„æ•°å€¼æ¢¯åº¦&quot;&quot;&quot;</span></span><br><span class="line">    grad = np.zeros_like(x)</span><br><span class="line">    h = <span class="number">1e-7</span>  <span class="comment"># ä¸€ä¸ªéå¸¸å°çš„å€¼</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(x.size):</span><br><span class="line">        temp_val = x[idx]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># è®¡ç®— f(x+h)</span></span><br><span class="line">        x[idx] = temp_val + h</span><br><span class="line">        fxh1 = f(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># è®¡ç®— f(x-h)</span></span><br><span class="line">        x[idx] = temp_val - h</span><br><span class="line">        fxh2 = f(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># æ•°å€¼æ¢¯åº¦</span></span><br><span class="line">        grad[idx] = (fxh1 - fxh2) / (<span class="number">2</span> * h)</span><br><span class="line">        x[idx] = temp_val  <span class="comment"># è¿˜åŸå€¼</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> grad</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_check</span>(<span class="params">f, grad_f, x</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;æ¯”è¾ƒæ•°å€¼æ¢¯åº¦å’Œåå‘ä¼ æ’­æ¢¯åº¦&quot;&quot;&quot;</span></span><br><span class="line">    num_grad = numerical_gradient(f, x)</span><br><span class="line">    backprop_grad = grad_f(x)</span><br><span class="line">    diff = np.linalg.norm(num_grad - backprop_grad) / (np.linalg.norm(num_grad) + np.linalg.norm(backprop_grad))</span><br><span class="line">    <span class="keyword">return</span> diff</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¤ºä¾‹å‡½æ•°å’Œå…¶æ¢¯åº¦</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_function</span>(<span class="params">theta</span>):</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(theta ** <span class="number">2</span>)  <span class="comment"># ç®€å•çš„äºŒæ¬¡å‡½æ•°</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_gradient</span>(<span class="params">theta</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * theta  <span class="comment"># äºŒæ¬¡å‡½æ•°çš„æ¢¯åº¦</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å‚æ•°åˆå§‹åŒ–</span></span><br><span class="line">theta = np.random.randn(<span class="number">3</span>)  <span class="comment"># å‡è®¾æœ‰ä¸‰ä¸ªå‚æ•°</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿›è¡Œæ¢¯åº¦æ£€éªŒ</span></span><br><span class="line">difference = gradient_check(loss_function, loss_gradient, theta)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Gradient difference: <span class="subst">&#123;difference&#125;</span>&#x27;</span>) <span class="comment"># Gradient difference: 2.7624883396806477e-10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å·®å¼‚åº”è¯¥éå¸¸å°ï¼Œä¾‹å¦‚å°äº 1e-7</span></span><br><span class="line"><span class="keyword">assert</span> difference &lt; <span class="number">1e-7</span>, <span class="string">&quot;æ¢¯åº¦æ£€éªŒå¤±è´¥ï¼Œåå‘ä¼ æ’­å®ç°å¯èƒ½æœ‰è¯¯&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="ä¼˜åŒ–ç®—æ³•"><a href="#ä¼˜åŒ–ç®—æ³•" class="headerlink" title="ä¼˜åŒ–ç®—æ³•"></a>ä¼˜åŒ–ç®—æ³•</h2><h3 id="Mini-Batch"><a href="#Mini-Batch" class="headerlink" title="Mini-Batch"></a>Mini-Batch</h3><p>Batchæ¢¯åº¦ä¸‹é™æ³•æ˜¯æœ€å¸¸ç”¨çš„æ¢¯åº¦ä¸‹é™å½¢å¼ï¼Œå³åŒæ—¶å¤„ç†æ•´ä¸ªè®­ç»ƒé›†ï¼Œä¸€æ¬¡éå†è®­ç»ƒé›†åªèƒ½è®©ä½ åšä¸€ä¸ªæ¢¯åº¦ä¸‹é™ã€‚<br>Mini-Batch æ¢¯åº¦ä¸‹é™æ³•æ¯æ¬¡åŒæ—¶å¤„ç†å•ä¸ªçš„ mini-batchï¼Œä¸€æ¬¡éå†è®­ç»ƒé›†ï¼Œèƒ½è®©ä½ åš mini-batch ä¸ªæ¢¯åº¦ä¸‹é™ã€‚</p>
<p><img data-src="/images/DeepLearning/minibatch_gradient_descent.png"></p>
<ul>
<li>Batchæ¢¯åº¦ä¸‹é™æ³•æ¯æ¬¡è¿­ä»£éƒ½ä¼šå†éæ•´ä¸ªè®­ç»ƒé›†ï¼Œæ¯æ¬¡è¿­ä»£æˆæœ¬éƒ½ä¼šä¸‹é™ï¼Œéšç€è¿­ä»£æ¬¡æ•°è€Œå‡å°‘ã€‚</li>
<li>Mini-Batchæ¢¯åº¦ä¸‹é™æ³•æ¯æ¬¡è¿­ä»£éƒ½åœ¨è®­ç»ƒä¸åŒçš„æ ·æœ¬é›†ï¼ˆä¸åŒçš„mini-batchï¼‰ï¼Œåœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­æˆæœ¬å‡½æ•°å¹¶ä¸æ˜¯æ¯æ¬¡<br>è¿­ä»£éƒ½ä¸‹é™ï¼Œä½†èµ°åŠ¿åº”è¯¥å‘ä¸‹ã€‚<ul>
<li>$mini-batch&#x3D;ğ‘š$ (æ•´ä¸ªè®­ç»ƒé›†)æ—¶ï¼Œç­‰åŒäº batch æ¢¯åº¦ä¸‹é™æ³•ã€‚<ul>
<li>æ¯ä¸€æ¬¡è¿­ä»£æ—¶é—´è¾ƒé•¿ï¼Œè®­ç»ƒè¿‡ç¨‹æ…¢ã€‚</li>
</ul>
</li>
<li>$mini-batch&#x3D;1$ æ—¶ï¼Œç§°ä¸ºéšæœºæ¢¯åº¦ä¸‹é™æ³•ï¼ˆstochastic gradient descentï¼‰ï¼Œæ¯ä¸ªæ ·æœ¬éƒ½æ˜¯ç‹¬ç«‹çš„ mini-batchã€‚<ul>
<li>è®­ç»ƒé€Ÿåº¦å¿«ï¼Œä½†ä¸¢å¤±äº†å‘é‡åŒ–å¸¦æ¥çš„è®¡ç®—åŠ é€Ÿ</li>
<li>æˆæœ¬å‡½æ•°æ€»ä½“è¶‹åŠ¿å‘å…¨å±€æœ€å°å€¼é è¿‘ï¼Œä½†æ°¸è¿œä¸ä¼šæ”¶æ•›ï¼Œè€Œæ˜¯ä¸€ç›´åœ¨æœ€å°å€¼é™„è¿‘æ³¢åŠ¨</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><p><strong>æŒ‡æ•°åŠ æƒå¹³å‡æ•°ï¼ˆExponentially Weighted Moving Average, EWMAï¼‰</strong>æ˜¯ä¸€ç§å¹³æ»‘æŠ€æœ¯ï¼Œç”¨äºå»å™ªå’Œè¶‹åŠ¿åˆ†æã€‚å®ƒé€šè¿‡å¯¹æ—¶é—´åºåˆ—æ•°æ®åº”ç”¨æŒ‡æ•°åŠ æƒæ¥è®¡ç®—å¹³å‡å€¼ï¼Œä½¿æœ€è¿‘çš„æ•°æ®ç‚¹å¯¹å¹³å‡å€¼çš„å½±å“æ›´å¤§ï¼Œè€Œè¾ƒæ—§çš„æ•°æ®ç‚¹å½±å“è¾ƒå°ã€‚å…¶å…¬å¼å¦‚ä¸‹ï¼š<br>$$ S_t &#x3D; Î±X_tâ€‹ + (1âˆ’Î±)S_{tâˆ’1} $$<br>$$ S_t æ˜¯æ—¶é—´ t çš„åŠ æƒå¹³å‡å€¼ï¼›S_{tâˆ’1} æ˜¯æ—¶é—´ tâˆ’1 çš„åŠ æƒå¹³å‡å€¼ $$<br>$$ X_t æ˜¯æ—¶é—´ t çš„å®é™…æ•°æ®å€¼ $$<br>$$ Î± æ˜¯å¹³æ»‘ç³»æ•°ï¼Œå–å€¼èŒƒå›´åœ¨ (0, 1) ä¹‹é—´ï¼Œé€šå¸¸è®¾å®šä¸ºæ¥è¿‘ 1 çš„å€¼ $$</p>
<ul>
<li>è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹åœ¨äºï¼Œå®ƒèƒ½å¤Ÿå¿«é€Ÿå“åº”æ•°æ®ä¸­çš„å˜åŒ–ï¼ŒåŒæ—¶ä¿ç•™å†å²æ•°æ®çš„å½±å“ã€‚<br>â€‹</li>
</ul>
<p><strong>Momentum ä¼˜åŒ–ç®—æ³•</strong>å’Œ EWMA çš„åŸºæœ¬æ€æƒ³éå¸¸ç›¸ä¼¼ï¼Œéƒ½æ˜¯é€šè¿‡æŒ‡æ•°åŠ æƒå¹³å‡çš„æ–¹æ³•æ¥å¹³æ»‘æ•°æ®ã€‚å…·ä½“æ¥è¯´ï¼ŒMomentum ä¼˜åŒ–ç®—æ³•å¯ä»¥çœ‹ä½œæ˜¯å¯¹æ¢¯åº¦çš„æŒ‡æ•°åŠ æƒå¹³å‡ï¼Œå®ƒé€šè¿‡ç´¯ç§¯è¿‡å»æ¢¯åº¦çš„åŠ¨é‡æ¥æ›´æ–°å‚æ•°ï¼Œä»è€ŒåŠ é€Ÿæ”¶æ•›å’Œå‡å°‘éœ‡è¡ã€‚å…¶å…¬å¼å¦‚ä¸‹ï¼š<br>$$ v_t &#x3D; Î²v_{tâˆ’1} + Î±âˆ‡J(Î¸) &#x3D; Î²v_{tâˆ’1} + (1-Î²)âˆ‡J(Î¸) $$<br>$$ Î¸ &#x3D; Î¸ âˆ’ v_tâ€‹ $$<br>$$ v_t æ˜¯å½“å‰æ—¶åˆ»çš„é€Ÿåº¦ï¼›Î± æ˜¯å­¦ä¹ ç‡ï¼ˆå¯å–å€¼ 1-Î²ï¼‰ï¼›âˆ‡J(Î¸) æ˜¯å½“å‰æ—¶åˆ»çš„æ¢¯åº¦ $$<br>$$ Î² æ˜¯åŠ¨é‡å› å­ï¼ˆé€šå¸¸å–å€¼åœ¨ 0 åˆ° 1 ä¹‹é—´ï¼‰ï¼Œé€šå¸¸å–å€¼ä¸ºÎ²&#x3D;0.9 $$<br>$$ PS: ä¼ ç»Ÿæ¢¯åº¦ä¸‹é™ç®—æ³•å…¬å¼ä¸º Î¸ &#x3D; Î¸ âˆ’ Î±âˆ‡J(Î¸)â€‹ $$</p>
<p>ç®—æ³•æ­¥éª¤ï¼š</p>
<ol>
<li>åˆå§‹åŒ–é€Ÿåº¦ $v&#x3D;0$ã€‚</li>
<li>è¿­ä»£æ›´æ–°ï¼š</li>
</ol>
<ul>
<li>è®¡ç®—å½“å‰çš„æ¢¯åº¦ $âˆ‡J(Î¸)$</li>
<li>æ›´æ–°é€Ÿåº¦ï¼š$v_t &#x3D; Î²v_{tâˆ’1} + Î±âˆ‡J(Î¸)$</li>
<li>æ›´æ–°å‚æ•°ï¼ˆæƒé‡wä¸åå·®bï¼‰ï¼šÎ¸ &#x3D; Î¸ âˆ’ v_t</li>
</ul>
<ol start="3">
<li>é‡å¤æ­¥éª¤ 2 ç›´åˆ°æ»¡è¶³ç»ˆæ­¢æ¡ä»¶ï¼ˆå¦‚è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°æˆ–æŸå¤±å‡½æ•°æ”¶æ•›ï¼‰ã€‚</li>
</ol>
<p>å½¢è±¡è§£é‡Šï¼š<br>å°†æˆæœ¬å‡½æ•°æƒ³è±¡ä¸ºä¸€ä¸ªç¢—çŠ¶ï¼Œä»é¡¶éƒ¨å¼€å§‹è¿åŠ¨çš„å°çƒå‘ä¸‹æ»šï¼Œå…¶ä¸­ $dw$ï¼Œ$db$ æƒ³è±¡æˆçƒçš„åŠ é€Ÿåº¦ï¼›è€Œ $vdw$ã€$vdb$ ç›¸å½“äºé€Ÿåº¦ã€‚<br>å°çƒåœ¨å‘ä¸‹æ»šåŠ¨çš„è¿‡ç¨‹ä¸­ï¼Œå› ä¸ºåŠ é€Ÿåº¦çš„å­˜åœ¨é€Ÿåº¦ä¼šå˜å¿«ï¼Œä½†æ˜¯ç”±äº $Î²$ çš„å­˜åœ¨ï¼Œå…¶å€¼å°äº 1ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯æ‘©æ“¦åŠ›ï¼Œæ‰€ä»¥çƒä¸ä¼šæ— é™åŠ é€Ÿä¸‹å»ã€‚</p>
<h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><p>RMSprop (Root Mean Square Propagationï¼Œå‡æ–¹æ ¹ä¼ æ’­) çš„çš„å…³é”®æ€æƒ³æ˜¯ä¿æŒä¸€ä¸ªç§»åŠ¨å¹³å‡æ•°ï¼ˆMoving Averageï¼‰æ¥ä¼°è®¡æ¢¯åº¦çš„å¹³æ–¹ï¼Œç„¶åä½¿ç”¨è¿™ä¸ªä¼°è®¡å€¼æ¥è°ƒæ•´å­¦ä¹ ç‡ã€‚è¿™æœ‰åŠ©äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç¨³å®šå‚æ•°æ›´æ–°ï¼Œé¿å…è¾ƒå¤§çš„æ¢¯åº¦å¯¼è‡´å­¦ä¹ ç‡è¿‡å¤§ï¼Œä»è€Œè·³å‡ºå±€éƒ¨æœ€ä¼˜è§£ã€‚<br>$$ æ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ï¼šE[g^2]_t &#x3D; \beta E[g^2]_{t-1} + (1 - \beta) g_t^2 $$<br>$$ å‚æ•°æ›´æ–°ï¼š\theta_{t+1} &#x3D; \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t $$<br>$$ E[g^2]_t æ˜¯æ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ $$<br>$$ Î² æ˜¯è¡°å‡ç‡ï¼Œæ§åˆ¶ç§»åŠ¨å¹³å‡çš„è®°å¿†é•¿åº¦ï¼Œé€šå¸¸å–å€¼åœ¨ 0.9 å·¦å³ã€‚ $$<br>$$ Î· æ˜¯å­¦ä¹ ç‡ $$<br>$$ Ïµ æ˜¯ä¸€ä¸ªå¾ˆå°çš„å€¼ï¼ˆå¦‚ 1Ã—10^{âˆ’8}ï¼‰ï¼Œç”¨äºé˜²æ­¢é™¤é›¶ã€‚ $$<br>$$ g_t æ˜¯å½“å‰æ¢¯åº¦ $$</p>
<ul>
<li>RMSProp æœ‰åŠ©äºå‡å°‘æŠµè¾¾æœ€å°å€¼è·¯å¾„ä¸Šçš„æ‘†åŠ¨ï¼Œå¹¶å…è®¸ä½¿ç”¨ä¸€ä¸ªæ›´å¤§çš„å­¦ä¹ ç‡ $Î±$ï¼Œä»è€ŒåŠ å¿«ç®—æ³•å­¦ä¹ é€Ÿåº¦ã€‚</li>
</ul>
<h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>Adam (Adaptive Moment Estimation) ç®—æ³•ç»“åˆäº† Momentum å’Œ RMSprop æ¢¯åº¦ä¸‹é™æ³•ï¼Œå¹¶ä¸”æ˜¯ä¸€ç§æå…¶å¸¸ç”¨çš„å­¦ä¹ ç®—æ³•ï¼Œè¢«è¯æ˜èƒ½æœ‰æ•ˆé€‚ç”¨äºä¸åŒç¥ç»ç½‘ç»œï¼Œé€‚ç”¨äºå¹¿æ³›çš„ç»“æ„ã€‚å…¶é€šè¿‡è®¡ç®—æ¢¯åº¦çš„ä¸€é˜¶çŸ©ï¼ˆåŠ¨é‡ï¼‰å’ŒäºŒé˜¶çŸ©ï¼ˆæ¢¯åº¦çš„å¹³æ–¹çš„æŒ‡æ•°åŠ æƒå¹³å‡ï¼‰æ¥è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ ç‡ã€‚è¿™ä½¿å¾—ç®—æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿè‡ªé€‚åº”åœ°è°ƒæ•´å­¦ä¹ ç‡ï¼Œä»è€ŒåŠ å¿«æ”¶æ•›é€Ÿåº¦å¹¶æé«˜è®­ç»ƒç¨³å®šæ€§ã€‚å…¶å…¬å¼å¦‚ä¸‹ï¼š<br>$$ ä¸€é˜¶çŸ©ä¼°è®¡ï¼ˆåŠ¨é‡ï¼‰ï¼šm_t &#x3D; \beta_1 m_{t-1} + (1 - \beta_1) g_t $$<br>$$ äºŒé˜¶çŸ©ä¼°è®¡ï¼ˆæ¢¯åº¦çš„å¹³æ–¹ï¼‰ï¼šv_t &#x3D; \beta_2 v_{t-1} + (1 - \beta_2) g_t^2 $$<br>$$ åå·®ä¿®æ­£ï¼š\hat{m}_t &#x3D; \frac{m_t}{1 - \beta_1^t}; \hat{v}_t &#x3D; \frac{v_t}{1 - \beta_2^t} $$<br>$$ å‚æ•°æ›´æ–°ï¼šÎ¸_{t+1} &#x3D; Î¸_t - \eta \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} $$<br>$$ ğ‘”_ğ‘¡ æ˜¯æ—¶é—´æ­¥ t çš„æ¢¯åº¦ï¼›m_t æ˜¯ä¸€é˜¶çŸ©ï¼ˆåŠ¨é‡ï¼‰ï¼›v_t æ˜¯äºŒé˜¶çŸ©ï¼ˆæ¢¯åº¦çš„å¹³æ–¹ï¼‰$$<br>$$ \hat{m}_t å’Œ \hat{v}_t æ˜¯ç»è¿‡åå·®ä¿®æ­£çš„ä¸€é˜¶çŸ©å’ŒäºŒé˜¶çŸ© $$<br>$$ Î²_1 å’Œ ğ›½_2 åˆ†åˆ«æ˜¯ä¸€é˜¶å’ŒäºŒé˜¶çŸ©çš„æŒ‡æ•°åŠ æƒè¡°å‡ç‡ï¼Œé€šå¸¸ ğ›½_1 &#x3D; 0.9 å’Œ ğ›½_2 &#x3D; 0.999 $$<br>$$ Î· æ˜¯å­¦ä¹ ç‡ï¼›Ïµ æ˜¯ä¸€ä¸ªå°å¸¸æ•°ï¼Œç”¨äºé˜²æ­¢é™¤é›¶ï¼Œé€šå¸¸å–10^{âˆ’8} $$</p>
<p>ç®—æ³•æ­¥éª¤ï¼š</p>
<ol>
<li>åˆå§‹åŒ–å‚æ•°ï¼šè®¾å®šåˆå§‹å‚æ•° $ğœƒ$ï¼Œä¸€é˜¶çŸ© $ğ‘š&#x3D;0$ å’ŒäºŒé˜¶çŸ© $ğ‘£&#x3D;0$ï¼Œæ—¶é—´æ­¥ $ğ‘¡&#x3D;0$ã€‚</li>
<li>æ›´æ–°æ—¶é—´æ­¥ï¼š$ğ‘¡ &#x3D; ğ‘¡ + 1$ã€‚</li>
<li>è®¡ç®—æ¢¯åº¦ï¼šè®¡ç®—å½“å‰å‚æ•° $ğœƒ$ ä¸‹çš„æ¢¯åº¦ $ğ‘”_ğ‘¡$ã€‚</li>
<li>æ›´æ–°ä¸€é˜¶çŸ©å’ŒäºŒé˜¶çŸ©ï¼šè®¡ç®— $m_t$ å’Œ $v_t$</li>
<li>è¿›è¡Œåå·®ä¿®æ­£ï¼šè®¡ç®—$\hat{m}_t$ å’Œ $\hat{v}_t$</li>
<li>æ›´æ–°å‚æ•°ï¼šè®¡ç®—$Î¸_{t+1}$</li>
<li>é‡å¤æ­¥éª¤ 2 åˆ° 6 ç›´åˆ°æ»¡è¶³ç»ˆæ­¢æ¡ä»¶ï¼ˆå¦‚è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°æˆ–æŸå¤±å‡½æ•°æ”¶æ•›ï¼‰ã€‚</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰ä¸€ä¸ªç®€å•çš„äºŒæ¬¡æŸå¤±å‡½æ•°</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_function</span>(<span class="params">theta</span>):</span><br><span class="line">    <span class="keyword">return</span> theta ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰æŸå¤±å‡½æ•°çš„æ¢¯åº¦</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">theta</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * theta</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆå§‹åŒ–å‚æ•°</span></span><br><span class="line">theta = <span class="number">10.0</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">beta1 = <span class="number">0.9</span></span><br><span class="line">beta2 = <span class="number">0.999</span></span><br><span class="line">epsilon = <span class="number">1e-8</span></span><br><span class="line">m = <span class="number">0.0</span></span><br><span class="line">v = <span class="number">0.0</span></span><br><span class="line">num_iterations = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Adam ä¼˜åŒ–ç®—æ³•</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, num_iterations + <span class="number">1</span>):</span><br><span class="line">    grad = gradient(theta)</span><br><span class="line">    m = beta1 * m + (<span class="number">1</span> - beta1) * grad</span><br><span class="line">    v = beta2 * v + (<span class="number">1</span> - beta2) * grad ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># åå·®ä¿®æ­£</span></span><br><span class="line">    m_hat = m / (<span class="number">1</span> - beta1 ** t)</span><br><span class="line">    v_hat = v / (<span class="number">1</span> - beta2 ** t)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ›´æ–°å‚æ•°</span></span><br><span class="line">    theta -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Iteration <span class="subst">&#123;t&#125;</span>: theta = <span class="subst">&#123;theta&#125;</span>, loss = <span class="subst">&#123;loss_function(theta)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Final parameters: theta = <span class="subst">&#123;theta&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Iteration 100: theta = 9.017435976334866, loss = 81.31415158729834</span></span><br><span class="line"><span class="comment"># Iteration 200: theta = 8.084813902170069, loss = 65.36421583272242</span></span><br><span class="line"><span class="comment"># Iteration 300: theta = 7.204569788364201, loss = 51.905825835410184</span></span><br><span class="line"><span class="comment"># Iteration 400: theta = 6.3776805733702, loss = 40.67480949594364</span></span><br><span class="line"><span class="comment"># Iteration 500: theta = 5.605075235194148, loss = 31.416868392186732</span></span><br><span class="line"><span class="comment"># Iteration 600: theta = 4.887571069967223, loss = 23.888350963980542</span></span><br><span class="line"><span class="comment"># Iteration 700: theta = 4.225799960920499, loss = 17.857385309715692</span></span><br><span class="line"><span class="comment"># Iteration 800: theta = 3.6201255435505493, loss = 13.10530895106716</span></span><br><span class="line"><span class="comment"># Iteration 900: theta = 3.0705548357573003, loss = 9.428306999392541</span></span><br><span class="line"><span class="comment"># Iteration 1000: theta = 2.576650248553287, loss = 6.639126503369717</span></span><br><span class="line"><span class="comment"># Final parameters: theta = 2.576650248553287</span></span><br></pre></td></tr></table></figure>

<h2 id="å­¦ä¹ ç‡è¡°å‡"><a href="#å­¦ä¹ ç‡è¡°å‡" class="headerlink" title="å­¦ä¹ ç‡è¡°å‡"></a>å­¦ä¹ ç‡è¡°å‡</h2><p>å­¦ä¹ ç‡è¡°å‡ï¼ˆLearning rate decayï¼‰æ˜¯æŒ‡éšæ—¶é—´æ…¢æ…¢å‡å°‘å­¦ä¹ ç‡ã€‚å­¦ä¹ ç‡æ˜¯ä¼˜åŒ–ç®—æ³•ä¸­çš„ä¸€ä¸ªé‡è¦è¶…å‚æ•°ï¼Œå®ƒå†³å®šäº†å‚æ•°æ›´æ–°çš„æ­¥é•¿å¤§å°ï¼Œå³åœ¨æ¯æ¬¡è¿­ä»£ä¸­å‚æ•°æ²¿ç€æ¢¯åº¦æ–¹å‘æ›´æ–°çš„å¹…åº¦ã€‚å­¦ä¹ ç‡è¡°å‡çš„ç›®çš„æ˜¯ä½¿å¾—æ¨¡å‹åœ¨è®­ç»ƒåˆæœŸèƒ½å¤Ÿæ›´å¿«åœ°æ”¶æ•›åˆ°æœ€ä¼˜è§£é™„è¿‘ï¼Œå¹¶åœ¨è®­ç»ƒåæœŸæ›´ç»†è‡´åœ°æœç´¢æœ€ä¼˜è§£ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚</p>
<h2 id="éç‚¹ï¼ˆsaddleï¼‰"><a href="#éç‚¹ï¼ˆsaddleï¼‰" class="headerlink" title="éç‚¹ï¼ˆsaddleï¼‰"></a>éç‚¹ï¼ˆsaddleï¼‰</h2><p>éç‚¹ï¼ˆsaddleï¼‰åœ¨æ·±åº¦å­¦ä¹ ä¸­æ˜¯æŒ‡æŸå¤±å‡½æ•°åœ¨æŸä¸ªæ–¹å‘ä¸Šæ˜¯å±€éƒ¨æœ€å°å€¼è€Œåœ¨å¦ä¸€ä¸ªæ–¹å‘ä¸Šæ˜¯å±€éƒ¨æœ€å¤§å€¼çš„ç‚¹ã€‚æ¢å¥è¯è¯´ï¼Œéç‚¹æ˜¯æŸå¤±å‡½æ•°çš„æ¢¯åº¦ä¸ºé›¶ä½†ä¸æ˜¯å…¨å±€æœ€ä¼˜ç‚¹çš„ä½ç½®ã€‚ï¼ˆæƒ³æƒ³æŸå¤±å‡½æ•°æ˜¯é©¬éå½¢çŠ¶çš„æ›²é¢ï¼Œä¾§é¢çœ‹æ˜¯é©¬èƒŒçš„é«˜ç‚¹æ˜¯æœ€å°æå€¼ï¼Œæ­£é¢çœ‹å®é™…è¿˜èƒ½ç»§ç»­å¾€ä¸¤ä¾§æ¢¯åº¦ä¸‹é™ï¼‰</p>
<p>éç‚¹çš„ç‰¹å¾ï¼š</p>
<ul>
<li>æ¢¯åº¦ä¸ºé›¶ï¼šåœ¨éç‚¹å¤„ï¼ŒæŸå¤±å‡½æ•°çš„æ¢¯åº¦ä¸ºé›¶ï¼Œå³æ²¿ç€è¯¥æ–¹å‘ä¸å†æœ‰æ˜æ˜¾çš„ä¸Šå‡æˆ–ä¸‹é™è¶‹åŠ¿ã€‚</li>
<li>éå…¨å±€æœ€ä¼˜ç‚¹ï¼šå°½ç®¡æ¢¯åº¦ä¸ºé›¶ï¼Œä½†éç‚¹ä¸æ˜¯å…¨å±€æœ€ä¼˜ç‚¹ï¼Œå› ä¸ºæŸå¤±å‡½æ•°åœ¨å…¶ä»–æ–¹å‘ä¸Šä»ç„¶å­˜åœ¨æ›´ä¼˜çš„ç‚¹ã€‚</li>
<li>å±€éƒ¨æå€¼ï¼šéç‚¹é€šå¸¸è¢«è®¤ä¸ºæ˜¯å±€éƒ¨æå€¼ï¼Œä½†å¹¶éæ˜¯å±€éƒ¨æœ€å°å€¼æˆ–å±€éƒ¨æœ€å¤§å€¼ï¼Œè€Œæ˜¯æŸå¤±å‡½æ•°åœ¨æŸä¸ªæ–¹å‘ä¸Šæ˜¯å±€éƒ¨æœ€å°å€¼è€Œåœ¨å¦ä¸€ä¸ªæ–¹å‘ä¸Šæ˜¯å±€éƒ¨æœ€å¤§å€¼ã€‚</li>
</ul>
<p>éç‚¹çš„å½±å“ï¼š</p>
<ul>
<li>ä¼˜åŒ–å›°éš¾ï¼šåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œå½“ç®—æ³•é‡åˆ°éç‚¹æ—¶ï¼Œæ¢¯åº¦ä¸‹é™å¯èƒ½ä¼šåœæ»ï¼Œå¯¼è‡´ä¼˜åŒ–è¿‡ç¨‹å˜æ…¢æˆ–é™·å…¥å±€éƒ¨æå€¼ç‚¹ã€‚</li>
<li>å‚æ•°æ›´æ–°ç¼“æ…¢ï¼šç”±äºæ¢¯åº¦æ¥è¿‘é›¶ï¼Œå‚æ•°æ›´æ–°ä¼šå˜å¾—éå¸¸ç¼“æ…¢ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜ç»´ç©ºé—´ä¸­ã€‚</li>
<li>ä¸ç¨³å®šæ€§ï¼šéç‚¹å¯èƒ½ä¼šå¯¼è‡´ä¼˜åŒ–ç®—æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸ç¨³å®šï¼Œä½¿å¾—æ¨¡å‹æ”¶æ•›å›°éš¾ã€‚</li>
</ul>
<p>å¦‚ä½•åº”å¯¹éç‚¹ï¼š</p>
<ul>
<li>ä½¿ç”¨æ›´å¤æ‚çš„ä¼˜åŒ–ç®—æ³•ï¼šæŸäº›ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚Adamï¼‰å¯¹éç‚¹å…·æœ‰æ›´å¥½çš„å¤„ç†èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¿«åœ°è·³å‡ºéç‚¹å¹¶ç»§ç»­ä¼˜åŒ–ã€‚</li>
<li>å¢åŠ éšæœºæ€§ï¼šéšæœºæ¢¯åº¦ä¸‹é™ç­‰å¸¦æœ‰ä¸€å®šéšæœºæ€§çš„ä¼˜åŒ–ç®—æ³•æœ‰åŠ©äºè·³å‡ºéç‚¹ï¼Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜è§£ã€‚</li>
<li>é™ä½å­¦ä¹ ç‡ï¼šåœ¨éç‚¹é™„è¿‘é™ä½å­¦ä¹ ç‡ï¼Œä½¿å¾—ç®—æ³•æ›´å®¹æ˜“è·³å‡ºéç‚¹ï¼Œé¿å…ä¼˜åŒ–è¿‡ç¨‹åœæ»ã€‚</li>
<li>åˆå§‹åŒ–ç­–ç•¥ï¼šè‰¯å¥½çš„å‚æ•°åˆå§‹åŒ–ç­–ç•¥æœ‰åŠ©äºé¿å…æ¨¡å‹é™·å…¥éç‚¹ã€‚</li>
</ul>
<h2 id="Softmaxå›å½’"><a href="#Softmaxå›å½’" class="headerlink" title="Softmaxå›å½’"></a>Softmaxå›å½’</h2><p>Softmaxå›å½’æ˜¯ä¸€ç§ç”¨äºå¤šåˆ†ç±»ä»»åŠ¡çš„å¹¿ä¹‰é€»è¾‘å›å½’æ–¹æ³•ï¼Œé€šè¿‡Softmaxå‡½æ•°å°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œå¹¶ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°è¿›è¡Œä¼˜åŒ–ã€‚</p>
<ul>
<li>ä¸é€»è¾‘å›å½’ä¸åŒï¼Œåè€…ä»…é™äºäºŒåˆ†ç±»ä»»åŠ¡ï¼Œè€ŒSoftmaxå›å½’èƒ½å¤Ÿå¤„ç†å¤šä¸ªç±»åˆ«çš„æƒ…å†µã€‚</li>
<li>Softmaxå›å½’é€šè¿‡è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼Œå¹¶é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«ä½œä¸ºé¢„æµ‹ç»“æœã€‚</li>
</ul>
<p>Softmaxå›å½’çš„å…·ä½“è¿‡ç¨‹ï¼š</p>
<ol>
<li>è¾“å…¥å’Œæ¨¡å‹è¾“å‡ºï¼šå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªè¾“å…¥å‘é‡ $ğ‘¥$ï¼Œå®ƒçš„ç»´åº¦æ˜¯ $ğ‘‘$ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é¢„æµ‹ $ğ¾$ ä¸ªç±»åˆ«ä¸­çš„ä¸€ä¸ªã€‚å› æ­¤ï¼Œæ¨¡å‹çš„è¾“å‡ºå°†æ˜¯ä¸€ä¸ª $ğ¾$ ç»´å‘é‡ï¼Œè¡¨ç¤ºæ¯ä¸ªç±»åˆ«çš„å¾—åˆ†ï¼ˆlogitsï¼‰ã€‚æ¨¡å‹çš„è¾“å‡ºå¯ä»¥è¡¨ç¤ºä¸º<br>$$ \mathbf{z} &#x3D; \mathbf{W}\mathbf{x} + \mathbf{b}ï¼Œå…¶ä¸­ï¼ŒW æ˜¯æƒé‡çŸ©é˜µï¼Œç»´åº¦ä¸º ğ¾Ã—ğ‘‘ï¼›b æ˜¯åç½®å‘é‡ï¼Œç»´åº¦ä¸º ğ¾ $$</li>
<li>è®¡ç®—Softmaxå‡½æ•°ï¼šSoftmaxå‡½æ•°å°†æ¨¡å‹çš„è¾“å‡ºè½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ<br>$$ \hat{y}_i &#x3D; \frac{e^{z_i}}{\sum_{j&#x3D;1}^K e^{z_j}}ï¼Œå…¶ä¸­ï¼Œ\hat{y}_i æ˜¯è¾“å…¥ ğ‘¥ å±äºç¬¬ ğ‘– ç±»çš„æ¦‚ç‡ $$<br><img data-src="/images/DeepLearning/softmax_function.png"></li>
<li>äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼šå¯¹äºå¤šåˆ†ç±»ä»»åŠ¡ï¼Œå¸¸ç”¨çš„æŸå¤±å‡½æ•°æ˜¯äº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ ·æœ¬ï¼Œå…¶çœŸå®æ ‡ç­¾ä¸º $ğ‘¦$ï¼Œç”¨one-hotç¼–ç è¡¨ç¤ºä¸ºå‘é‡ $ğ‘¦$ã€‚äº¤å‰ç†µæŸå¤±å‡½æ•°å®šä¹‰ä¸ºï¼š<br>$$ L(\mathbf{y}, \hat{\mathbf{y}}) &#x3D; -\sum_{i&#x3D;1}^K y_i \log(\hat{y}_i) $$<br>one-hotç¼–ç ç¤ºä¾‹ï¼š<br><img data-src="/images/DeepLearning/onehot_encode.png"></li>
<li>å‚æ•°æ›´æ–°ï¼ˆæ¢¯åº¦ä¸‹é™ï¼‰ï¼šä¸ºäº†æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥æ›´æ–°æ¨¡å‹çš„å‚æ•°ï¼ˆ$ğ‘Š$ å’Œ $ğ‘$ï¼‰</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºä¸€äº›æ ·æœ¬æ•°æ®</span></span><br><span class="line">num_classes = <span class="number">3</span>  <span class="comment"># ç±»åˆ«çš„æ•°é‡ï¼ˆ3ç±»ï¼‰</span></span><br><span class="line">num_features = <span class="number">4</span> <span class="comment"># æ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾æ•°ï¼ˆ4ä¸ªç‰¹å¾ï¼‰</span></span><br><span class="line">num_samples = <span class="number">10</span> <span class="comment"># æ ·æœ¬æ•°é‡ï¼ˆ10ä¸ªæ ·æœ¬ï¼‰</span></span><br><span class="line">np.random.seed(<span class="number">42</span>) <span class="comment"># è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡å¤</span></span><br><span class="line">X_data = np.random.rand(num_samples, num_features).astype(np.float32) <span class="comment"># ç”Ÿæˆå½¢çŠ¶ä¸º(10, 4)çš„éšæœºæµ®ç‚¹æ•°æ•°ç»„ï¼Œè¡¨ç¤ºæ ·æœ¬çš„ç‰¹å¾</span></span><br><span class="line">y_data = np.random.randint(num_classes, size=num_samples) <span class="comment"># ç”Ÿæˆå½¢çŠ¶ä¸º(10,)çš„éšæœºæ•´æ•°æ•°ç»„ï¼Œè¡¨ç¤ºæ ·æœ¬çš„çœŸå®æ ‡ç­¾ã€‚</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºæ•°æ®é›†ï¼ˆå°†æ ·æœ¬æ•°æ®å’Œæ ‡ç­¾åˆ›å»ºä¸ºä¸€ä¸ªTensorFlowæ•°æ®é›†ï¼Œå¹¶å°†å…¶åˆ†æˆæ‰¹æ¬¡ï¼Œæ¯æ‰¹æ¬¡åŒ…å«5ä¸ªæ ·æœ¬ï¼‰</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((X_data, y_data)).batch(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ„å»ºæ¨¡å‹ï¼ˆä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œè¾“å‡ºç»´åº¦ä¸ºç±»åˆ«æ•°ï¼ˆ3ï¼‰ï¼Œæ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼‰</span></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Dense(num_classes, activation=<span class="literal">None</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># é€‰æ‹©ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°</span></span><br><span class="line">optimizer = tf.keras.optimizers.SGD(learning_rate=<span class="number">0.01</span>) <span class="comment"># é€‰æ‹©éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ä¸º0.01</span></span><br><span class="line">loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>) <span class="comment"># é€‰æ‹©ç¨€ç–åˆ†ç±»äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œå‚æ•°from_logits=Trueè¡¨ç¤ºè¾“å…¥æ˜¯logits</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒæ¨¡å‹</span></span><br><span class="line">epochs = <span class="number">100</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs): <span class="comment"># è¿­ä»£100ä¸ªè®­ç»ƒè½®æ¬¡</span></span><br><span class="line">    <span class="keyword">for</span> X_batch, y_batch <span class="keyword">in</span> dataset: <span class="comment"># è¿­ä»£æ•°æ®é›†çš„æ¯ä¸ªæ‰¹æ¬¡</span></span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape: <span class="comment"># è®°å½•è®¡ç®—æ¢¯åº¦çš„æ“ä½œ</span></span><br><span class="line">            logits = model(X_batch) <span class="comment"># é€šè¿‡æ¨¡å‹å‰å‘ä¼ æ’­è®¡ç®—logits</span></span><br><span class="line">            loss = loss_fn(y_batch, logits) <span class="comment"># è®¡ç®—å½“å‰æ‰¹æ¬¡çš„æŸå¤±</span></span><br><span class="line"></span><br><span class="line">        gradients = tape.gradient(loss, model.trainable_variables) <span class="comment"># è®¡ç®—æŸå¤±å¯¹æ¨¡å‹å‚æ•°çš„æ¢¯åº¦</span></span><br><span class="line">        optimizer.apply_gradients(<span class="built_in">zip</span>(gradients, model.trainable_variables)) <span class="comment"># åº”ç”¨æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, Loss: <span class="subst">&#123;loss.numpy()&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># é¢„æµ‹</span></span><br><span class="line">logits = model(X_data) <span class="comment"># é€šè¿‡æ¨¡å‹å‰å‘ä¼ æ’­è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„logits</span></span><br><span class="line">predictions = tf.argmax(logits, axis=<span class="number">1</span>) <span class="comment"># æ‰¾åˆ°æ¯ä¸ªæ ·æœ¬logitsä¸­æœ€å¤§å€¼çš„ç´¢å¼•ï¼Œä½œä¸ºé¢„æµ‹ç±»åˆ«</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Predictions: <span class="subst">&#123;predictions.numpy()&#125;</span>&#x27;</span>) <span class="comment"># æ‰“å°é¢„æµ‹ç»“æœ</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;True labels: <span class="subst">&#123;y_data&#125;</span>&#x27;</span>) <span class="comment"># æ‰“å°çœŸå®æ ‡ç­¾</span></span><br><span class="line"><span class="comment"># Epoch 10, Loss: 0.8509548902511597</span></span><br><span class="line"><span class="comment"># Epoch 20, Loss: 0.8373783230781555</span></span><br><span class="line"><span class="comment"># Epoch 30, Loss: 0.8273806571960449</span></span><br><span class="line"><span class="comment"># Epoch 40, Loss: 0.8200419545173645</span></span><br><span class="line"><span class="comment"># Epoch 50, Loss: 0.8146781921386719</span></span><br><span class="line"><span class="comment"># Epoch 60, Loss: 0.8107778429985046</span></span><br><span class="line"><span class="comment"># Epoch 70, Loss: 0.8079572916030884</span></span><br><span class="line"><span class="comment"># Epoch 80, Loss: 0.8059269189834595</span></span><br><span class="line"><span class="comment"># Epoch 90, Loss: 0.8044678568840027</span></span><br><span class="line"><span class="comment"># Epoch 100, Loss: 0.8034144639968872</span></span><br><span class="line"><span class="comment"># Predictions: [1 1 1 0 1 1 1 1 1 1]</span></span><br><span class="line"><span class="comment"># True labels: [2 0 2 2 1 0 1 1 1 1]</span></span><br></pre></td></tr></table></figure>

<h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><p><a target="_blank" rel="noopener" href="https://github.com/fengdu78/deeplearning_ai_books">æ·±åº¦å­¦ä¹ æ•™ç¨‹ä¸­æ–‡ç¬”è®°</a><br><a target="_blank" rel="noopener" href="https://github.com/WithHades/deep_learning">å´æ©è¾¾æ·±åº¦å­¦ä¹ ä½œä¸š</a><br><a target="_blank" rel="noopener" href="https://kyonhuang.top/Andrew-Ng-Deep-Learning-notes">ã€Šæ·±åº¦å­¦ä¹ ã€‹è¯¾ç¨‹ç¬”è®°</a><br><a target="_blank" rel="noopener" href="https://dennybritz.com/posts/wildml/implementing-a-neural-network-from-scratch/">Implementing a Neural Network from Scratch in Python</a><br><a target="_blank" rel="noopener" href="https://github.com/imssyang/python/tree/main/sample/custom/deeplearning">deeplearning_code</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/DeepLearning/" rel="tag"><i class="fa fa-tag"></i> DeepLearning</a>
              <a href="/tags/ArtificialIntelligence/" rel="tag"><i class="fa fa-tag"></i> ArtificialIntelligence</a>
              <a href="/tags/NeuralNetwork/" rel="tag"><i class="fa fa-tag"></i> NeuralNetwork</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/ProgrammingLanguage/Swift/Basic.html" rel="prev" title="SwiftåŸºç¡€">
                  <i class="fa fa-chevron-left"></i> SwiftåŸºç¡€
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/DeepLearning/CNN.html" rel="next" title="å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰">
                  å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2020 â€“ 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-burn"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ssyang</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Symbols count total">492k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">7:27</span>
  </span>
</div>
  <div class="powered-by"><a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a>/<a href="https://theme-next.js.org/mist/" class="theme-link" rel="noopener" target="_blank">NexT</a>
  </div>

    </div>
  </footer>

  
  <script src="/lib/animejs/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="/lib/@next-theme/pjax/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
  <script src="/lib/jquery/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="/lib/@fancyapps/fancybox/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="/lib/medium-zoom/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/lib/lozad/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="/lib/pangu/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  
<script src="/lib/hexo-generator-searchdb/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"/lib/pdfobject/pdfobject.min.js","integrity":"sha256-ph3Dk89VmuTVXG6x/RDzk53SU9LPdAh1tpv0UvnDZ2I="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"/lib/mermaid/dist/mermaid.min.js","integrity":"sha256-CmZCFVnvol9YL23PfjDflGY5nJwE+Mf/JN+8v+tD/34="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>

  <script src="/js/third-party/fancybox.js"></script>


  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"/lib/mathjax/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="/lib/quicklink/dist/quicklink.umd.js" integrity="sha256-4kQf9z5ntdQrzsBC3YSHnEz02Z9C1UeW/E9OgnvlzSY=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://blog.imssyang.com/DeepLearning/Basic.html"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<link rel="stylesheet" href="/lib/disqusjs/dist/disqusjs.css" integrity="sha256-GxdCIOyfxQ1OBfS99qAIJDoGK1ADuBsxhMTqXG82fAY=" crossorigin="anonymous">

<script class="next-config" data-name="disqusjs" type="application/json">{"enable":true,"api":"https://disqus.com/api/","apikey":"9zaN2jW6zXMHxC3NctLnrVsVuNe4yZ8CyZ1rWAJQKcIc7JMaHNPP9m4vra2AJeIA","shortname":"imssyang","js":{"url":"/lib/disqusjs/dist/disqus.js","integrity":"sha256-LVaMHPQ2zLqOc5rXSAfr4d1PIkEGNLyyUTDNPZmTtUw="}}</script>
<script src="/js/third-party/comments/disqusjs.js"></script>

</body>
</html>
